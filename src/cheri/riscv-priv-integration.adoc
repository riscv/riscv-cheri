[#section_priv_cheri]
== "{cheri_priv_m_ext}/{cheri_priv_s_ext}" Extensions, Version 1.0

ifdef::cheri_standalone_spec[]
WARNING: This chapter will appear in the priv spec. Exact location TBD.
endif::[]

This chapter describes integration of {cheri_base_ext_name} with the RISC-V privileged architecture.

=== CHERI fault reporting

CHERI faults require additional information to be reported.
The CSRs updated depend on the mode the trap is taken into, as shown in
<<cheri-fault-reporting>>.

The additional information is written for CHERI faults and <<cheri_pte_fault,CHERI PTE page faults>>, and
is otherwise written to zero for all other exceptions, except as listed otherwise by other
future extensions.

.CHERI fault reporting
[#cheri-fault-reporting,width=65%,float="center",align="center",options=header,cols="1,1,1"]
|==============================================================================
| Trap taken into  | Faulting address | Additional CHERI fault information
| M-mode           | <<mtval>>        | <<mtval2>>
| HS-mode / S-mode | <<stval>>        | <<stval2>>
| VS-mode          | <<vstval>>       | <<vstval2>>
|==============================================================================

=== Machine-Level CSRs added or extended by {cheri_priv_m_ext}

{cheri_base_ext_name} extends some M-mode CSRs to hold capabilities or
otherwise add new functions. <<asr_perm>> in the <<pcc>> is typically required for access.

[#mtvecc,reftext="mtvecc"]
==== Machine Trap Vector Base Address Capability Register (mtvecc)

The <<mtvecc>> register extends <<mtvec>> to hold a code capability.
Its reset value is the <<infinite-cap>> capability.

.Machine-mode trap-vector base-capability register
include::img/mtveccreg.edn[]

The metadata is WARL as not all fields need to be implemented, for example the
reserved fields will always read as zero.

When interpreting <<mtvecc>> as a capability, as for <<mtvec>>, address bits
[1:0] are always zero (as they are reused by the MODE field).

When MODE=Vectored, all synchronous exceptions into machine mode
cause the <<pcc>> to be set to the capability, whereas
interrupts cause the <<pcc>> to be set to the capability with
its address incremented by four times the interrupt cause number.

Capabilities written to <<mtvecc>> also include writing the MODE field in
**mtvecc.address[1:0]**, which is a WARL field, meaning that the capability address can
be legalized. If the MODE field is non-zero after any legalization,
then the address used for the exception vector (which has **mtvecc.address[1:0]=2'b00**)
will not match the value read by software from the CSR.

When updating the CSR _all possible_ values of the address visible either by CSR read,
or which are used as the <<pcc>> on exception launch, must be in the
<<section_cap_representable_check>>, and the validity tag cleared if _any_ are not.

The capability is always written using <<SCADDR>> semantics to update the address field,
even when writing the full capability, and so sealed capabilities will always have
their tags cleared.

Additionally, when MODE=Vectored the capability has its tag bit cleared if the
`(capability address & ~3) + 4 * HICAUSE` is not within the <<section_cap_representable_check>>.
HICAUSE is the largest interrupt cause value that the implementation can write
to <<mcause>> or <<scause>>/<<vscause>> when an interrupt is taken.

NOTE: When MODE=Vectored, it is only required that the capability address + `4 *  HICAUSE` is
within the <<section_cap_representable_check>> instead of the capability's bounds.
This ensures
that software is not forced to allocate a capability granting access to more
memory for the trap-vector than necessary to handle the trap causes that
actually occur in the system.

NOTE: When MODE=Vectored, if either the capability address _or_ the capability
address + `4 * HICAUSE` are invalid then the <<section_invalid_addr_conv>> rules
are followed which may require the validity tag to be cleared. In particular, if any part
of the range is in the invalid address space then clearing the validity tag is strongly
recommended.

As shown in xref:CSR_exevectors[xrefstyle=short], <<mtvecc>> is a code capability, so it does not need to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).

[#mscratchc, reftext="mscratchc"]
==== Machine Scratch Capability Register (mscratchc)

The <<mscratchc>> register extends <<mscratch>> to hold a capability.

{TAG_RESET_CSR}

It is not WARL, all capability fields must be implemented.

.Machine-mode scratch capability register
include::img/mscratchcreg.edn[]

[#mepcc,reftext="mepcc"]
==== Machine Exception Program Counter Capability (mepcc)

The <<mepcc>> register extends <<mepc>> to hold a capability.
Its reset value is the <<infinite-cap>> capability.

.Machine exception program counter capability register
include::img/mepccreg.edn[]

Capabilities written to <<mepcc>> must be legalized by implicitly zeroing bit
**mepcc[0]**. Additionally, if an implementation allows IALIGN to be
either 16 or 32, then whenever IALIGN=32, the capability read from <<mepcc>>
must be legalized by implicitly zeroing **mepcc[1]**. Therefore, the
capability read or written has its tag bit cleared if the legalized address is
not within the <<section_cap_representable_check>> or if the legalization
changes the address and the capability is sealed.

NOTE: When reading or writing a sealed capability in <<mepcc>>, the
tag is not cleared if the original address equals the legalized
address.

When a trap is taken into M-mode, <<mepcc>> is written with the <<pcc>>
including the virtual address of the instruction that was interrupted or that
encountered an exception. Otherwise, <<mepcc>> is never written by the
implementation, though it may be explicitly written by software.

As shown in xref:CSR_exevectors[xrefstyle=short], <<mepcc>> is a code capability, so it does not need to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).
Additionally, the capability in <<mepcc>> is unsealed when it is installed in
<<pcc>> on execution of an <<MRET>> instruction.

=== Machine-Level CSRs modified by {cheri_priv_m_ext}

==== Machine Status Registers (mstatus and mstatush)

The *mstatus* and *mstatush* registers operate as described in
<<mstatus>> with two restrictions:

* The <<xlen-control, SXL and UXL>> fields that control the
value of XLEN for S-mode and U-mode must be read-only in implementations supporting {cheri_base_ext_name}.
  Only 1 and 2 are supported values for SXL and UXL

* The <<endianness-control,MBE, SBE, and UBE>> fields that control the memory system endianness for M-mode, S-mode, and U-mode must be read-only in implementations supporting {cheri_base_ext_name}.
   SBE and UBE must be read only and equal to MBE, if S-mode or
U-mode, respectively, is implemented, or read-only zero otherwise.

Changing XLEN or endianness would change the interpretation of all in-memory capabilities, so allowing these fields to change at runtime is prohibited.

NOTE: These restrictions are relaxed if a further privileged CHERI extension, {cheri_priv_m_dyn_xlen_ext}, optionally makes SXL,
UXL, MBE, SBE, and UBE writeable, to support CHERI on implementations that support dynamic XLEN or endianness changes.

[[cheri-mcause]]
==== Machine Cause Register (mcause)

{cheri_base_ext_name} adds a new exception code for CHERI exceptions that <<mcause>> must be able to represent.
The new exception code and its priority are listed in xref:mcauses[xrefstyle=short] and xref:exception-priority[xrefstyle=short] respectively.
The behavior and usage of <<mcause>> otherwise remains as described in xref:mcause[xrefstyle=short].

WARNING: The current specification uses the CHERI ISAv9 mcause value of {cheri_excep_mcause}, which is designated for custom extensions.

IMPORTANT: #The exact code as well as the mechanism to report subcodes needs to be finalized: https://github.com/riscv/riscv-cheri/issues/536#

If an instruction may raise multiple synchronous exceptions, the decreasing priority order of <<exception-priority-cheri>> indicates which exception is taken and reported in `mcause`.
This table extends the existing priority order from <<exception-priority>> with new entries.

IMPORTANT: Once finalized this table should be merged with the main table.

[[exception-priority-cheri]]
.Synchronous exception priority in decreasing priority order. Entries added in {cheri_base_ext_name} are in *bold*
[float="center",align="center",cols="<1,>1,<8",options="header"]
|===
|Priority |Exc.Code |Description
|_Highest_ |3 |Instruction address breakpoint
| .>|*{cheri_excep_mcause}* .<|*Prior to instruction address translation:* +
*CHERI fault due to PCC checks (tag, execute permission, invalid address and bounds^1^)*
| .>|12, 1 .<|During instruction address translation: +
First encountered page fault or access fault
| .>|1 .<|With physical address for instruction: +
Instruction access fault

| .>|2 +
0 +
8,9,11 +
3 +
3 .<|Illegal instruction +
Instruction address misaligned +
Environment call +
Environment break +
Load/store/AMO address breakpoint

| .>| *{cheri_excep_mcause}* .<| *CHERI faults due to:* +
*PCC <<asr_perm>> clear* +
*Branch/jump target address checks (tag, execute permissions, invalid address and bounds)*

| .>|*{cheri_excep_mcause}* .<|*Prior to address translation for an explicit memory access:* +
*CHERI fault due to capability checks (tag, sealed, permissions, invalid address and bounds)*
| .>|4,6 .<|*Load/store/AMO capability address misaligned* +
Optionally: +
Load/store/AMO address misaligned
| .>|13, 15, 5, 7 .<|During address translation for an explicit memory access: +
First encountered *<<cheri_pte_ext,CHERI PTE page fault>>*^23^, page fault or access fault
| .>|5,7 .<|With physical address for an explicit memory access: +
Load/store/AMO access fault
| .>|4,6 .<|If not higher priority: +
Load/store/AMO address misaligned
.>|_Lowest_ .>|13 .<|*If not higher priority: +
CHERI load PTE page fault^4^*
|===

^1^ PCC bounds are intended to be checked against all the bytes of fetched instructions.
 In the case of variable length instruction encoding, and that the fetch has failed to return any data, then only a minimum length instruction is checked against the PCC bounds.

^2^ The higher priority <<cheri_pte_ext,CHERI PTE page fault>> covers capability loads or atomics where the loaded tag _is not_ checked, and all capability stores and atomics where the stored tag is set.

^3^ <<cheri_pte_ext,CHERI PTE page fault>> exceptions have the same priority against access faults as normal RISC-V page faults. If a normal RISC-V page fault _and_ a <<cheri_pte_ext,CHERI PTE page fault>> are both detected simultaneously, then both are recorded as shown in <<mtval2-page-fault>>.

^4^ The lower priority <<cheri_pte_ext,CHERI PTE page fault>> only covers capability loads and atomics where the loaded tag _is_ checked.

NOTE: The full details of the CHERI exceptions with cause value {cheri_excep_mcause} are in xref:cheri_exception_combs_descriptions[xrefstyle=short].

==== Machine Trap Delegation Register (medeleg)

Bit {cheri_excep_mcause} of <<medeleg>> now refers to a valid exception and so can be used to
delegate CHERI exceptions to supervisor mode.

[[mtval-cheri]]
==== Machine Trap Value Register (mtval)

ifdef::cheri_v9_annotations[]
WARNING: *CHERI v9 Note:* Encoding and values changed, and generally were
simplified.
endif::[]

The <<mtval>> register is an MXLEN-bit read-write register formatted as shown
in xref:mtval-format[xrefstyle=short]. When a data memory access gives rise to
a CHERI fault taken into M-mode, <<mtval>> is written with the
MXLEN-bit effective address which caused the fault according to the existing
rules for reporting load/store addresses. In this case
the TYPE field of <<mtval2>> shown in xref:mtval2-cheri-type[xrefstyle=short] is
set to {cheri_excep_type_data}. For all other CHERI faults <<mtval>> is set to zero.

The behavior of <<mtval>> is otherwise as described in xref:mtval[xrefstyle=short].

If the hardware platform specifies that no exceptions set <<mtval>> to a
non-zero value, then <<mtval>> is read-only zero for all CHERI exceptions.

.Machine trap value register
[#mtval-format]
include::img/mtvalreg.edn[]

[#mtval2,reftext="mtval2"]
==== Machine Trap Value Register 2 (mtval2)

ifdef::cheri_v9_annotations[]
WARNING: *CHERI v9 Note:* This CSR was not part of CHERIv9.
endif::[]

The <<mtval2>> register is an MXLEN-bit read-write register, which is added as part of the
Hypervisor extension cite:[riscv-priv-spec]. {cheri_base_ext_name} also requires the implementation of this CSR.

When a CHERI fault, or <<cheri_pte_ext,CHERI PTE page fault>>, is taken into M-mode, <<mtval2>> is written
with additional CHERI-specific exception information with the format shown in
xref:mtval2-format[xrefstyle=short] to assist software in handling the trap.

<<mtval2>> is written to zero for all other exceptions, except as listed otherwise by
the Hypervisor extension in cite:[riscv-priv-spec], or by other future extensions.

NOTE: the use of <<mtval2>>/<<stval2>>/<<vstval2>> may be irregular as the Hypervisor uses
 <<mtval2>> and _htval_ for guest page addresses on guest page fault, and CHERI has no use for _htval_.

If <<mtval>> is read-only zero for CHERI exceptions then <<mtval2>> is also read-only zero
for CHERI exceptions.

===== mtval2 values for CHERI faults

.Machine trap value register 2 format for CHERI Faults
[#mtval2-format]
include::img/mtval2reg.edn[]

NOTE: <<mtval2>> is also used for Hypervisor guest physical addresses, and so the implemented bits must also cover that use case.
 If Hypervisor is not implemented then all WPRI fields in <<mtval2-format>> are read-only-zero.

TYPE is a CHERI-specific fault type that caused the exception while CAUSE
is the cause of the fault. The possible CHERI types and causes are encoded as
shown in xref:mtval2-cheri-type[xrefstyle=short] and
xref:mtval2-cheri-causes[xrefstyle=short] respectively.

.Encoding of TYPE field for CHERI Faults
[#mtval2-cheri-type,width=65%,float="center",align="center",options=header,cols="30%,70%"]
|==============================================================================
| CHERI Type Code           | Description
| {cheri_excep_type_pcc}    | CHERI instruction fetch fault
| {cheri_excep_type_data}   | CHERI data fault due to load, store or AMO
| {cheri_excep_type_jump}   | CHERI jump or branch fault
| 3-15                      | Reserved
|==============================================================================

.Encoding of CAUSE field
[#mtval2-cheri-causes,width=55%,float="center",align="center",options=header]
|==============================================================================
| CHERI Cause Code              | Description
| {cheri_excep_cause_tag}       | Tag violation
| {cheri_excep_cause_seal}      | Seal violation
| {cheri_excep_cause_perm}      | Permission violation
| {cheri_excep_cause_inv_addr}  | Invalid address violation
| {cheri_excep_cause_bounds}    | Bounds violation
| 5-15                          | Reserved
|==============================================================================

CHERI violations have the following order in priority:

. Tag violation (_Highest_)
. Seal violation
. Permission violation
. Invalid address violation
. Bounds violation (_Lowest_)

===== mtval2 values for Load/Store/AMO Page Faults

Page faults can be caused by normal RISC-V page faults and also by CHERI <<cheri_pte_ext,PTE>> faults.
If both are detected at once, then both are recorded.

.mtval2 for page faults
[#mtval2-page-fault,width=70%,float="center",align="center",cols="2,1",options=header]
|==============================================================================
| Fault                                                        | Value
| RISC-V page fault                                            | 0
| <<cheri_pte_ext,CHERI PTE page fault>>                       | 1
| RISC-V page fault and <<cheri_pte_ext,CHERI PTE page fault>> | 2
|==============================================================================

NOTE: Reporting both allows the software the choice about which action to take first, for example a write to a
 page with no write permission, _and_ the incorrect value of PTE.CRG requires two actions.
 Software can then decide whether to prioritize the copy-on-write procedure to fix the lack of write
 permission, or to sweep the page.

[#supervisor-level-csrs-section]
=== Supervisor-Level CSRs added or extended by {cheri_priv_s_ext}

{cheri_base_ext_name} extends some of the existing RISC-V CSRs to be able to
hold capabilities or with other new functions. <<asr_perm>> in the <<pcc>> is typically required for access.

[#stvecc,reftext="stvecc"]
==== Supervisor Trap Vector Base Address Capability Register (stvecc)

The <<stvecc>> register extends <<stvec>> that is able to hold a capability.
Its reset value is the <<infinite-cap>> capability.

.Supervisor trap-vector base-capability register
include::img/stveccreg.edn[]

The handling of <<stvecc>> is otherwise identical to <<mtvecc>>, but in supervisor mode.

[#sscratchc, reftext="sscratchc"]
==== Supervisor Scratch Capability Register (sscratchc)

The <<sscratchc>> register extends <<sscratch>> to hold a capability.

{TAG_RESET_CSR}

It is not WARL, all capability fields must be implemented.

.Supervisor scratch capability register
include::img/sscratchcreg.edn[]

[#sepcc,reftext="sepcc"]
==== Supervisor Exception Program Counter Capability (sepcc)

The <<sepcc>> register extends <<sepc>> to hold a capability.
Its reset value is the <<infinite-cap>> capability.

As shown in xref:CSR_exevectors[xrefstyle=short], <<sepcc>> is a code capability, so it does not need to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).
Additionally, the capability in <<sepcc>> is unsealed when it is installed in <<pcc>> on execution of an <<SRET>> instruction.
The handling of <<sepcc>> is otherwise identical to <<mepcc>>, but in supervisor mode.

.Supervisor exception program counter capability register
include::img/sepccreg.edn[]

[#stval2,reftext="stval2"]
==== Supervisor Trap Value Register 2 (stval2)

The <<stval2>> register is an SXLEN-bit read-write register, which is added as
part of {cheri_priv_s_ext} when the implementation supports S-mode. Its CSR
address is 0x14b.

<<stval2>> is updated following the same rules as <<mtval2>> for CHERI exceptions
and <<cheri_pte_fault,CHERI PTE page faults>> which are delegated to HS-mode or S-mode.
It is written to zero for all other exceptions, except as listed otherwise by other
future extensions.

NOTE: Unlike <<mtval2>>, <<stval2>> is a new a CSR added by {cheri_priv_s_ext}.

IMPORTANT: #The mechanism to report exception subcodes needs to be finalized: https://github.com/riscv/riscv-cheri/issues/536#

.Supervisor trap value register 2
[#stval2-format]
include::img/stval2reg.edn[]

=== Supervisor-Level CSRs modified by {cheri_priv_s_ext}
==== Supervisor Cause Register (scause)

{cheri_base_ext_name} adds a new exception code for CHERI exceptions that <<scause>> must be able to represent.
The new exception code is listed in xref:scauses[xrefstyle=short].
The behavior and usage of <<scause>> otherwise remains as described in xref:scause[xrefstyle=short].

See <<cheri-mcause>> for the new exceptions priorities when {cheri_base_ext_name} is implemented.

[[stval-cheri]]
==== Supervisor Trap Value Register (stval)

<<stval>> is updated following the same rules as <<mtval-cheri>> for CHERI exceptions
and <<cheri_pte_fault,CHERI PTE page faults>> which are delegated to HS-mode or S-mode.


=== CHERI Exception handling

NOTE: `auth_cap` is <<ddc>> for {cheri_int_mode_name} and `cs1` for {cheri_cap_mode_name}

.Valid CHERI exception combination description
[#cheri_exception_combs_descriptions]
[width="100%",options=header,cols="2,1,1,1,3,4"]
|=========================================================================================
| Instructions | Xcause | Xtval2. TYPE | Xtval2. CAUSE | Description | Check
6+| *All instructions have these exception checks first*
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_tag}      | <<pcc>> tag             | not(<<pcc>>.tag)
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_seal}     | <<pcc>> seal            | isCapSealed(<<pcc>>)^1^
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_perm}     | <<pcc>> permission      | not(<<pcc>>.<<x_perm>>)
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_inv_addr} | <<pcc>> invalid address | <<pcc>> holds an invalid address
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_bounds}   | <<pcc>> bounds          | Any byte of current instruction out of <<pcc>> bounds
6+| *CSR/Xret additional exception check*
| CSR*, <<MRET>>, <<SRET>> | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_perm}          | <<pcc>> permission | not(<<pcc>>.<<asr_perm>>) when required for CSR access or execution of <<MRET>>/<<SRET>>
6+| *direct jumps additional exception check*
| <<JAL_CHERI>>, <<insns-conbr-32bit>> | {cheri_excep_mcause} | {cheri_excep_type_jump} | {cheri_excep_cause_bounds} | <<pcc>> bounds     | any byte of minimum length instruction at target out of <<pcc>> bounds
6+| *indirect jumps additional exception checks*
| indirect jumps | {cheri_excep_mcause} | {cheri_excep_type_jump} | {cheri_excep_cause_tag}      |`cs1` tag             | not(`cs1.tag`)
| indirect jumps | {cheri_excep_mcause} | {cheri_excep_type_jump} | {cheri_excep_cause_seal}     |`cs1` seal            | isCapSealed(`cs1`) and imm12 != 0
| indirect jumps | {cheri_excep_mcause} | {cheri_excep_type_jump} | {cheri_excep_cause_perm}     |`cs1` permission      | not(`cs1`.<<x_perm>>)
| indirect jumps | {cheri_excep_mcause} | {cheri_excep_type_jump} | {cheri_excep_cause_inv_addr} |`cs1` invalid address | target address is an invalid address
| indirect jumps | {cheri_excep_mcause} | {cheri_excep_type_jump} | {cheri_excep_cause_bounds}   |`cs1` bounds          | any byte of minimum length instruction at target out of `cs1` bounds
6+| *Load additional exception checks*
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_tag}      | `auth_cap` tag             | not(`auth_cap.tag`)
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_seal}     | `auth_cap` seal            | isCapSealed(`auth_cap`)
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_perm}     | `auth_cap` permission      | not(`auth_cap`.<<r_perm>>)
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_inv_addr} | `auth_cap` invalid address | Address is invalid (see <<section_invalid_addr_conv>>)
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_bounds}   | `auth_cap` bounds          | Any byte of load access out of `auth_cap` bounds
| capability loads | 4                    | N/A                     | N/A                          | load address misaligned    | Misaligned capability load
6+| *Store/atomic/cache-block-operation additional exception checks*
| all stores, all atomics, all cbos              | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_tag}    |`auth_cap` tag        | not(`auth_cap.tag`)
| all stores, all atomics, all cbos              | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_seal}   |`auth_cap` seal       | isCapSealed(`auth_cap`)
| all atomics, CBO.INVAL*                        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_perm}   |`auth_cap` permission | not(`auth_cap`.<<r_perm>>)
| all stores, all atomics, CBO.INVAL*, CBO.ZERO* | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_perm}   |`auth_cap` permission | not(`auth_cap`.<<w_perm>>)
| CBO.CLEAN*, CBO.FLUSH*                         | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_perm}   |`auth_cap` permission | not(`auth_cap`.<<r_perm>>) and not(`auth_cap`.<<w_perm>>)
| all stores, all atomics, all cbos              | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_inv_addr} |`auth_cap` invalid address | Address is invalid (see <<section_invalid_addr_conv>>)
| all stores, all atomics                        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_bounds}   |`auth_cap` bounds          | any byte of access out of `auth_cap` bounds
| CBO.ZERO*, CBO.INVAL*                          | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_bounds}   |`auth_cap` bounds          | any byte of cache block out of `auth_cap` bounds
| CBO.CLEAN*, CBO.FLUSH*                         | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_bounds}   |`auth_cap` bounds          | all bytes of cache block out of `auth_cap` bounds
| CBO.INVAL*                                     | {cheri_excep_mcause} | {cheri_excep_type_pcc}  | {cheri_excep_cause_perm}     |<<pcc>> permission         | not(<<pcc>>.<<asr_perm>>)
| capability stores                              | 6                    | N/A                     | N/A                          |capability alignment       | Misaligned capability store
|=========================================================================================

^1^ This check is architecturally required, but is impossible to encounter so may not required in an implementation.

NOTE: Indirect branches are <<JALR_CHERI>>, conditional branches are <<insns-conbr-32bit>>.

NOTE: <<CBO.ZERO>> issues as a cache block wide store.  All
CMOs operate on the cache block which contains the address.  Prefetches check
that the capability is tagged, not sealed, has the permission (<<r_perm>>,
<<w_perm>>, <<x_perm>>) corresponding to the instruction, and has bounds which
include at least one byte of the cache block; if any check fails, the prefetch
is not performed but no exception is generated.

[#CHERI_SPEC,reftext="CHERI Exceptions and speculative execution"]
=== CHERI Exceptions and speculative execution

CHERI adds architectural guarantees that can prove to be microarchitecturally useful.
Speculative-execution attacks can -- among other factors -- rely on instructions that fail CHERI permission checks not to take effect.
When implementing any of the extensions proposed here, microarchitects need to carefully consider the interaction of late-exception raising and side-channel attacks.

[#section_pma]
=== Physical Memory Attributes (PMA)

Typically, the entire memory space need not support tagged data. Therefore, it
is desirable that harts supporting {cheri_base_ext_name} extend PMAs with a
_taggable_ attribute indicating whether a memory region allows storing tagged
data.

Data loaded from memory regions that are not taggable will always have the validity tag
cleared. When the hart attempts to store data with the validity tag set to memory regions
that are not taggable, the implementation may:

* Cause an access fault exception
* Implicitly set the stored tag to 0

=== Page-Based Virtual-Memory Systems

RISC-V's page-based virtual-memory management is generally orthogonal to CHERI.
In {cheri_base_ext_name}, capability addresses are interpreted with respect to
the privilege level of the processor in line with RISC-V's handling of integer
addresses. In machine mode, capability addresses are generally interpreted as
physical addresses; if the <<mstatus>> MPRV flag is asserted, then data
accesses (but not instruction accesses) will be interpreted as if performed by
the privilege mode in mstatus's MPP. In supervisor and user modes, capability
addresses are interpreted as dictated by the current *satp* configuration:
addresses are virtual if paging is enabled and physical if not.

{cheri_base_ext_name} requires that the <<pcc>> grants the <<asr_perm>> to
change the page-table root *satp* and other virtual-memory parameters as
described in xref:supervisor-level-csrs-section[xrefstyle=short].

[#section_invalid_addr_conv,reftext="Invalid address conversion"]
==== Invalid Address Handling

When address translation is in effect and XLEN=64, the upper bits of virtual
memory addresses must match for the address to be valid:

* For Sv39, bits [63:39] must equal bit 38
* For Sv48, bits [63:48] must equal bit 47
* For Sv57, bits [63:57] must equal bit 56

RISC-V permits that CSRs holding addresses, such as <<mtvec>> and <<mepc>>
(see xref:CSR_exevectors[xrefstyle=short]) as well as pc, need not
hold all possible invalid addresses. Implementations may convert an invalid
address into some other invalid address that the register is capable of holding.
Therefore, implementations often support area and power optimizations by
compressing invalid addresses in a lossy fashion.

Where compressed addresses are implemented, there must be also sufficient address bits
to represent all valid physical addresses. The following description is for both
virtual and physical addresses.

NOTE: Compressing invalid addresses allows implementations to reduce the number
of flip-flops required to hold some CSRs, such as <<mtvec>>. In CHERI, invalid
addresses may also be used to reduce the number of bits to compare during a
bounds check, for example, to 40 bits if using Sv39, assuming that this also
covers all valid physical addresses.

NOTE: Care needs to be taken not to truncate physical addresses to the implemented
number of physical addresses bits without also checking that the capability is still
valid following the rules in this section, as the capability bounds and representable range
always cover the entire MXLEN-bit address bits, but the address is likely not to.

However, the bounds encoding of capabilities in {cheri_base_ext_name} depends
on the address value, so implementations must not convert invalid addresses to
other arbitrary invalid address in an unrestricted manner. The remainder of
this section describes how invalid address handling must be supported in
{cheri_base_ext_name} when accessing CSRs, branching and jumping, and
accessing memory.

===== Updating CSRs

Some capability-holding CSRs need not be able to hold all invalid virtual addresses.
Prior to writing to those CSRs, implementations may convert an invalid address into some other invalid address that the CSR is capable of holding.
This is problematic for CHERI as updating the address may invalidate the bounds as a result, if the bounds are not those of the <<infinite-cap>> capability.

Some situations may require that a CSR may be updated to hold a capability with an invalid address:

* executing instructions, such as <<CSRRW>>
* hardware updates to CSRs such as storing the <<pcc>> (which becomes capability A) into
 <<mepcc>>/<<sepcc>> etc. when taking an exception.

In order to satisfy the definitions of such CSRs and preserve capability system invariants, the following procedure must be used as part of write-back to the CSR:

. If A's address is invalid and A does not have infinite bounds (see
xref:section_cap_encoding[xrefstyle=short]), then A's tag is set to 0.
. Write the final (potentially modified) version of capability A to the CSR e.g.
<<mtvecc>>, <<mepcc>>, etc.

NOTE: When A's address is invalid and happens to match an invalid address which the CSR
can hold, then it is implementation defined whether to clear A's tag.

===== Branches and Jumps

Control transfer instructions jump or branch to a capability A which can be:

* <<pcc>> for branches, direct jumps and any branch when in
{cheri_int_mode_name} (see xref:section_cheri_hybrid_ext[xrefstyle=short]).
* The capability in the *c* input register of a jump when in
{cheri_cap_mode_name} (see xref:section_cheri_hybrid_ext[xrefstyle=short]).

The following procedure must be used when jumping or branching to the target
capability A if the <<pcc>> cannot hold all invalid addresses:

. Calculate the effective target address T of the jump or branch as required by
the instruction's behavior.
. If T is invalid and A does not have infinite bounds (see
xref:section_cap_encoding[xrefstyle=short]), then the instruction gives rise to
a CHERI fault; the _CHERI jump or branch_ fault is reported in the TYPE field
and invalid address violation is reported in the CAUSE field of <<mtval2>>,
<<stval2>> or <<vstval2>>.
. If T is invalid and A has infinite bounds (see
xref:section_cap_encoding[xrefstyle=short]), then A's tag is unchanged and T is
written into A's address field. Attempting to execute the instruction at
address T gives rise to an instruction access fault or page fault as is usual in RISC-V.
. Otherwise T is valid and the instruction behaves as normal.

NOTE: RISC-V harts that do not support {cheri_base_ext_name} normally raise an
instruction access fault or page fault after jumping or branching to an invalid address.
Therefore, {cheri_base_ext_name} aims to preserve that behavior to ensure that
harts supporting {cheri_base_ext_name} and {cheri_default_ext_name} are fully
compatible with RISC-V harts provided that <<pcc>> and <<ddc>> are set to the
<<infinite-cap>> capability.

===== Memory Accesses

The following procedure must be used while loading or storing to memory with a
capability A when the implementation supports invalid address optimizations:

. Calculate the effective address range R of the memory access as required by the
instruction's behavior.
. If any byte in R is invalid and A does not have infinite bounds (see
xref:section_cap_encoding[xrefstyle=short]), then the instruction gives rise to
a CHERI fault; the _CHERI data_ fault is reported in the TYPE field and invalid
address violation is reported in the CAUSE field of <<mtval2>>, <<stval2>> or <<vstval2>>.
. If any byte in R is invalid and A has infinite bounds (see xref:section_cap_encoding[xrefstyle=short]),
the hart will raise an access fault or page fault as is usual in RISC-V.
. Otherwise all bytes in R are valid and the instruction behaves as normal.

[#section_cheri_disable]
== "{cheri_priv_m_reg_enable_ext}" Extension, Version 1.0

ifdef::cheri_v9_annotations[]
NOTE: *CHERI v9 Note:* This feature is new and different from CHERI v9's
per-privilege enable bits.

NOTE: *CHERI v9 Note:* The rules for excepting have been tightened here. Also,
it is not possible to disable CHERI checks completely.
endif::[]

#FIXME: The CBZE, CBIE etc. bits are specified by Zicbo*, can this be defined by {cheri_priv_m_ext}/{cheri_priv_s_ext}+{cheri_default_ext_name} instead of adding a new priv extension?#

When using a system with {cheri_default_ext_name}, it may be desirable to disabling CHERI register and instruction access to some (or all) privilege levels such that they operate as a RV32I/RV64I system without any observable presence of CHERI features.
{cheri_priv_m_reg_enable_ext} includes functions to disable explicit access to CHERI
registers and instructions.
The {cheri_priv_m_reg_enable_ext} extension makes the `CRE` bit of <<mseccfg>>, <<menvcfg>>, and <<senvcfg>> writable.

IMPORTANT: If {cheri_base_ext_name} is supported and {cheri_default_ext_name} is not supported, then {cheri_priv_m_reg_enable_ext} must also not be supported.
  In this case all CRE bits are hardwired to 1 and access to CHERI registers is always permitted.
  This allows implementing a hart that always runs in {cheri_cap_mode_name}.

CHERI register access is disabled if

* XLEN in the current mode is less than MXLEN, or
* the endianness in the current mode is not the reset value of <<mstatus>>.MBE, or
* the effective CRE for the current privilege is 0.

The effective CRE for the current privilege is:

* Machine: `<<mseccfg>>.CRE`
* Supervisor: `<<mseccfg>>.CRE & <<menvcfg>>.CRE`
* User: `<<mseccfg>>.CRE & <<menvcfg>>.CRE & <<senvcfg>>.CRE`

NOTE: The effective CRE is always 1 in debug mode.

NOTE: On reset CHERI register access is disabled (<<mseccfg>>.CRE resets to zero).

The following occurs when executing code in a privilege mode that has CHERI register access disabled:

* The CHERI instructions that access capability registers (implicitly or explicitly)
cause illegal instruction exceptions
+
NOTE: The only instruction added by {cheri_base_ext_name} that does not access capability state is <<CRAM>>, all others are disabled.
* Executing CSR instructions accessing any CSR added by any CHERI extension ({cheri_default_ext_name}, {cheri_priv_m_ext}, {cheri_priv_s_ext}, {cheri_priv_h_ext}) causes an illegal instruction exception
* Executing CSR instructions accessing any CSR extended to CLEN only allows XLEN access.
* All allowed instructions execute as if the CHERI execution mode is {cheri_int_mode_name}.
// FIXME: there should be no way to observe the M bit, do we need to mentions this?
// The mode bit in <<pcc>> is treated as if it was zero while CHERI register access is disabled.

Disabling CHERI register access has no effect on implicit accesses or security checks.
The last capability installed in <<pcc>> and <<ddc>> before disabling CHERI register access will be used to authorize instruction execution and data memory accesses.

[NOTE]
====
Disabling CHERI register access prevents low-privileged {cheri_int_mode_name} software
from interfering with the correct operation of higher-privileged {cheri_int_mode_name} software
that do not perform <<ddc>> switches on trap entry and return.

Disabling CHERI register access allows harts supporting CHERI to be fully
compatible with standard RISC-V, so CHERI instructions, such as <<CRAM>>, that
do not change the state of CHERI CSRs raise exceptions when CRE=0.
This is the default behavior on reset.
====

xref:cheri_behavior_cre_mode[xrefstyle=short] summarizes the behavior of a hart
in connection with the <<section_cheri_disable,CRE>> and the <<section-cheri-execution-mode>> while in a privilege other than debug mode.

.Hart's behavior depending on the effective <<section_cheri_disable,CRE>> and <<section-cheri-execution-mode>>
[#cheri_behavior_cre_mode,width=100%,options=header,align=center,%autowidth,cols="40,20,20,20"]
|==============================================================================
| | CRE=0, M-bit=X^1^ | CRE=1, M-bit={int_mode_value} | CRE=1, M-bit={cap_mode_value}
| Authorizing capability for memory accesses | <<ddc>> or <<pcc>> | <<ddc>> or <<pcc>> | Instruction's capability operand
| New CHERI CSR Access Width                | ✘                 | CLEN                  | CLEN
| Extended CHERI CSR Access Width      | XLEN              | XLEN                  | CLEN
| CHERI Instructions Allowed           | ✘                 | ✔                    | ✔
| Compressed Instructions Remapped     | No                | No                    | Yes^2^
| Summary                              | **_Fully RISC-V compatible_**^3^ | **{cheri_int_mode_name}** | **{cheri_cap_mode_name}**
|==============================================================================

^1^ M-bit is irrelevant when CRE=0. +
^2^ See xref:legacy_mnemonics[xrefstyle=short] for a list of remapped
instructions. +
^3^ The hart is fully compatible with standard RISC-V when CRE=0 provided that <<pcc>>, <<mtvecc>>, <<mepcc>>, <<stvecc>>, <<sepcc>>, <<vstvecc>>, <<vsepcc>> and <<ddc>> have not been changed from the default reset state (i.e. hold the <<infinite-cap>> capability).


[#section_hybrid_priv]
=== Changes to the privileged architecture for {cheri_default_ext_name}

[#mstatus_hybrid]
==== Machine Status Registers (mstatus and mstatush)

{cheri_default_ext_name} eliminates some restrictions for SXL and UXL imposed in
{cheri_base_ext_name} to allow implementations supporting multiple base ISAs.
Namely, the SXL and UXL fields may be writable.

Setting the SXL or UXL field to a value that is not MXLEN disables most
CHERI features and instructions, as described in
xref:section_cheri_disable[xrefstyle=short], while in that privilege mode.

NOTE: If CHERI register access must be disabled in a mode for security reasons,
software should set CRE to 0 regardless of the SXL and UXL fields.

Whenever XLEN in any mode is set to a value less than MXLEN, standard RISC-V
rules from cite:[riscv-unpriv-spec] are followed. This means that all operations
must ignore source operand register bits above the configured XLEN, and must
sign-extend results to fill all MXLEN bits in the destination register.
Similarly, *pc* bits above XLEN are ignored, and when the *pc* is written, it
is sign-extended to fill MXLEN. The integer writing rule from CHERI is
followed, so that every register write also zeroes the metadata and tag of the
destination register.

However, CHERI operations and security checks will continue using the entire
hardware register (i.e. CLEN bits) to correctly decode capability bounds.

{cheri_default_ext_name} eliminates some restrictions for MBE, SBE, and UBE
imposed in {cheri_base_ext_name} to allow implementations supporting multiple
endiannesses.  Namely, the MBE, SBE, and UBE fields may be writable if the
corresponding privilege mode is implemented.

Setting the MBE, SBE, or UBE field to a value that is not the reset value of
MBE disables most CHERI features and instructions, as described in
xref:section_cheri_disable[xrefstyle=short], while in that privilege mode.

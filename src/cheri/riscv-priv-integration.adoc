[#section_priv_cheri]
== "{cheri_priv_m_ext}/{cheri_priv_s_ext}" Extensions, Version 1.0

ifdef::cheri_standalone_spec[]
WARNING: This chapter will appear in the priv spec. Exact location TBD.
endif::[]

This chapter describes integration of {cheri_base_ext_name} with the RISC-V privileged architecture.

=== Machine-Level CSRs added or extended by {cheri_priv_m_ext}

{cheri_base_ext_name} extends some M-mode CSRs to hold capabilities or
otherwise add new functions. <<asr_perm>> in the <<pcc>> is typically required for access
to the CSRs.

[#mtvecc,reftext="mtvecc"]
==== Machine Trap Vector Base Address Capability Register (mtvecc)

The <<mtvecc>> register extends <<mtvec>> to hold a code capability.
Its reset value is nominally the <<infinite-cap>> capability.

NOTE: <<mtvecc>> exists in all CHERI implementations, and so may be used as a source of the <<infinite-cap>> capability after reset.

.Machine-mode trap-vector base-capability register
include::img/mtveccreg.edn[]

The fields in the metadata are WARL as many fields can be implemented as constants.

NOTE: Examples of WARL behavior include always setting <<x_perm>> to 1 and setting the reserved fields to zero, otherwise the capability is unusable.
 Another example is to partially or fully restrict the bounds to constant values.

NOTE: Care must be taken however that an <<infinite-cap>> capability is available to software after reset if this CSR does not represent one.

When traps are taken into machine mode, the pc is updated following the standard `mtvec` behavior.
The {ctag} and metadata from <<mtvecc>> are also written to the <<pcc>>.

Following the standard `mtvec` behavior, the value of `mtvecc.address` can be viewed with a range of different addresses:

. The MODE field is included in `mtvecc.address[1:0]` but it does not form part of the trap vector address.
. When MODE=Vectored, the trap vector address is incremented by four times the interrupt number.
. CSR reads include MODE in `mtvecc.address[1:0]`.

`HICAUSE` is defined to be the largest interrupt cause value that the implementation can write
to `Xcause` when an interrupt is taken.

Therefore the minimum observable address is `mtvecc.address & ~3` and the maximum is `(mtvecc.address & ~3) + 4 x HICAUSE`.

All possible observable values must be in the <<section_cap_representable_check>>.
Software must ensure this is true when writing to <<mtvecc>>, and the hardware sets the {ctag} to zero if any values are out of the <<section_cap_representable_check>>.

NOTE: Modifying the address of any capability outside of the <<section_cap_representable_check>> without clearing the {ctag} causes a security hole as the interpretation of the bounds changes.
Therefore requiring that all possible observable addresses are representable but not necessary in bounds is the minimum security requirement.

<<mtvecc>> is always updated using <<SCADDR>> semantics and so writing a sealed capability will cause the {ctag} to be set to zero.

NOTE: The capability in <<mtvecc>> is _not_ unsealed when it is written to <<pcc>>, unlike other executing from other CSRs such as <<mepcc>>.

<<mtvecc>> follows the rule from `mtvec` about not needing to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).

[#mscratchc, reftext="mscratchc"]
==== Machine Scratch Capability Register (mscratchc)

The <<mscratchc>> register extends <<mscratch>> to hold a capability.

{TAG_RESET_MCSR}

It is not WARL, all capability fields must be implemented.

.Machine-mode scratch capability register
include::img/mscratchcreg.edn[]

[#mepcc,reftext="mepcc"]
==== Machine Exception Program Counter Capability (mepcc)

The <<mepcc>> register extends <<mepc>> to hold a capability.
Its reset value is nominally the <<infinite-cap>> capability.

.Machine exception program counter capability register
include::img/mepccreg.edn[]

`mepcc.address` is the `mepc` CSR, and so the follows the standard rules meaning that:

.  `mepcc.address[0]=0`, and
.  `mepcc.address[1]=0` when IALIGN is fixed to 32
.  `mepcc.address[1]` reads as zero when IALIGN is programmable and is set to 32

As listed above for <<mtvecc>>, this means that `mepcc.address` can represent multiple different values.
Therefore software must ensure that all possible values are in the <<section_cap_representable_check>> on writing, otherwise the hardware sets the written {ctag} to zero.

Sealed capabilities may be written to <<mepcc>>.
The {ctag} is set to zero on writing if:

.  `mepcc.address[0]=1`, or
.  `mepcc.address[1]=1` when IALIGN=32

In the following case the value of the {ctag} observable in the CSR depends on the value of IALIGN:

. <<mepcc>> is sealed, the {ctag} is set, and
. `mepcc.address[1]=1` and IALIGN=16 when writing the CSR

The {ctag} is zero then IALIGN=32 when reading the CSR, or executing <<MRET_CHERI>>, and the {ctag} is one when IALIGN=16.

When a trap is taken into M-mode, the pc is written to `mepcc.address` following the standard behavior.
The {ctag} and metadata of the <<pcc>> are also written to <<mepcc>>.

The capability in <<mepcc>> is unsealed when it is written to <<pcc>> on execution of an <<MRET_CHERI>> instruction.

<<mepcc>> follows the rule from `mepc` about not needing to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).

[#mtidc,reftext="mtidc"]
==== Machine Thread Identifier Capability (mtidc)

The <<mtidc>> register is used to identify the current software thread in machine mode, using the method defined in the section for the unprivileged <<utidc>> CSR.
On reset the {ctag} of <<mtidc>> will be set to zero and the remainder
of the data is UNSPECIFIED.

.Machine thread identifier capability register
include::img/mtidcreg.edn[]

=== Machine-Level CSRs modified by {cheri_priv_m_ext}

[#mstatus_cheri]
==== Machine Status Registers (mstatus and mstatush)

The *mstatus* and *mstatush* registers operate as described in
<<mstatus_cheri>> with two restrictions:

* The <<xlen-control, SXL and UXL>> fields that control the
value of XLEN for S-mode and U-mode must be read-only in implementations supporting {cheri_base_ext_name}.
  Only 1 and 2 are supported values for SXL and UXL

* The <<endianness-control,MBE, SBE, and UBE>> fields that control the memory system endianness for M-mode, S-mode, and U-mode must be read-only in implementations supporting {cheri_base_ext_name}.
   SBE and UBE must be read only and equal to MBE, if S-mode or
U-mode, respectively, is implemented, or read-only zero otherwise.

Changing XLEN or endianness would change the interpretation of all in-memory capabilities, so allowing these fields to change at runtime is prohibited.

NOTE: These restrictions are relaxed if a further privileged CHERI extension, {cheri_priv_m_dyn_xlen_ext}, optionally makes SXL,
UXL, MBE, SBE, and UBE writeable, to support CHERI on implementations that support dynamic XLEN or endianness changes.

CAUTION:: #ARC-QUESTION: Does {cheri_priv_m_dyn_xlen_ext} need to be a separate extension or just a "if xME,xXL bits are writable, then this behavior is followed" note in {cheri_priv_m_ext}#

<<mstatus_cheri>>.MXR has no effect on the CHERI permission checking.

NOTE: CHERI does not need to make use execute only memory for security reasons, and so MXR has no relevance.
 Additionally the 32-bit encoding format does not allow <<x_perm>> to be encoded without <<r_perm>>.

[[cheri-mcause]]
==== Machine Cause Register (mcause)

{cheri_base_ext_name} adds a new exception code for CHERI exceptions that <<mcause>> must be able to represent.
The new exception code and its priority are listed in xref:mcauses[xrefstyle=short] and xref:exception-priority[xrefstyle=short] respectively.
The behavior and usage of <<mcause>> otherwise remains as described in xref:mcause[xrefstyle=short].

#This table needs to be merged with the main table once we've resolve the Xcause type#

[[exception-priority-cheri]]
.Synchronous exception priority in decreasing priority order. Entries added in {cheri_base_ext_name} are in *bold*
[float="center",align="center",cols="<1,>1,<8",options="header"]
|===
|Priority |Exc.Code |Description
|_Highest_ |3 |Instruction address breakpoint
| .>|*{cheri_excep_cause_pc}* .<|*Prior to instruction address translation:* +
*CHERI fault due to PCC checks (tag, execute permission, bounds^1^)*
| .>|12, 1 .<|During instruction address translation: +
First encountered page fault or access fault
| .>|1 .<|With physical address for instruction: +
Instruction access fault

| .>|2 +
0 +
8,9,11 +
3 +
3 .<|Illegal instruction +
Instruction address misaligned +
Environment call +
Environment break +
Load/store/AMO address breakpoint

| .>| *{cheri_excep_cause_pc}* .<| *CHERI faults due to:* +
*PCC <<asr_perm>> clear* +
*Branch/jump target address checks (tag, execute permissions, bounds)*

| .>|*{cheri_excep_cause_ls_list}* .<|*Prior to address translation for an explicit memory access:* +
*CHERI fault due to capability checks (tag, sealed, permissions, bounds)*
| .>|4,6 .<|*Load/store/AMO capability address misaligned* +
Optionally: +
Load/store/AMO address misaligned
| .>|13, 15, 5, 7 .<|During address translation for an explicit memory access: +
First encountered *{cheri_excep_name_pte_ld}^2^, {cheri_excep_name_pte_st}*, page fault or access fault
| .>|5,7 .<|With physical address for an explicit memory access: +
Load/store/AMO access fault
| .>|4,6 .<|If not higher priority: +
Load/store/AMO address misaligned
.>|_Lowest_ .>|13 .<|*If not higher priority: +
*{cheri_excep_name_pte_ld}^3^*
|===

^1^ PCC bounds are checked against all bytes of fetched instructions.
 If the instructions could not be decoded to determine the length, then the <<pcc>> bounds check is made against the minimum sized instruction supported by the implementation which can be executed, when prioritizing against Instruction Access Faults.

^2^ The higher priority {cheri_excep_name_pte_ld} covers capability loads or atomics where the loaded {ctag} _is not_ checked ({cheri_priv_crg_ext} is implemented) .

^3^ The lower priority {cheri_excep_name_pte_ld} covers capability loads or atomics where the loaded {ctag} _is_ checked ({cheri_priv_crg_load_tag_ext} is implemented).

NOTE: The full details of the CHERI exceptions are in xref:cheri_exception_combs_descriptions[xrefstyle=short].

==== Machine Trap Delegation Register (medeleg)

Bits {cheri_excep_cause_list} of <<medeleg>> refer to a valid CHERI exception and so can be used to
delegate CHERI exceptions to supervisor mode.

[[mtval-cheri]]
==== Machine Trap Value Register (mtval)

ifdef::cheri_v9_annotations[]
WARNING: *CHERI v9 Note:* Encoding and values changed, and generally were
simplified.
endif::[]

For all CHERI faults, <<mtval>> is written with the MXLEN-bit effective address which caused the fault.

.Machine trap value register
[#mtval-format]
include::img/mtvalreg.edn[]

==== "Smstateen/Ssstateen" Integration
The TID bit in `mstateen0` controls access to the <<stidc>> CSR.

.Machine State Enable 0 Register (`mstateen0`)
[wavedrom, ,svg]
....
{reg: [
{bits: 1, name: 'C'},
{bits: 1, name: 'FCSR'},
{bits: 1, name: 'JVT'},
{bits: 1, name: 'TID'},
{bits: 52, name: 'WPRI'},
{bits: 1, name: 'P1P13'},
{bits: 1, name: 'CONTEXT'},
{bits: 1, name: 'IMSIC'},
{bits: 1, name: 'AIA'},
{bits: 1, name: 'CSRIND'},
{bits: 1, name: 'WPRI'},
{bits: 1, name: 'ENVCFG'},
{bits: 1, name: 'SE0'},
], config: {bits: 64, lanes: 4, hspace:1024}}
....


[#supervisor-level-csrs-section]
=== Supervisor-Level CSRs added or extended by {cheri_priv_s_ext}

{cheri_base_ext_name} extends some of the existing RISC-V CSRs to be able to
hold capabilities or with other new functions. <<asr_perm>> in the <<pcc>> is typically required for access to these CSRs.

[#stvecc,reftext="stvecc"]
==== Supervisor Trap Vector Base Address Capability Register (stvecc)

The <<stvecc>> register extends <<stvec>> that is able to hold a capability.
When the S-mode execution environment starts, the value is nominally the <<infinite-cap>> capability.

.Supervisor trap-vector base-capability register
include::img/stveccreg.edn[]

The handling of <<stvecc>> is otherwise identical to <<mtvecc>>, but in supervisor mode.

[#sscratchc, reftext="sscratchc"]
==== Supervisor Scratch Capability Register (sscratchc)

The <<sscratchc>> register extends <<sscratch>> to hold a capability.

{TAG_RESET_SCSR}

It is not WARL, all capability fields must be implemented.

.Supervisor scratch capability register
include::img/sscratchcreg.edn[]

[#sepcc,reftext="sepcc"]
==== Supervisor Exception Program Counter Capability (sepcc)

The <<sepcc>> register extends <<sepc>> to hold a capability.
Its reset value is the <<infinite-cap>> capability.

As shown in xref:CSR_exevectors[xrefstyle=short], <<sepcc>> is a code capability, so it does not need to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).
Additionally, the capability in <<sepcc>> is unsealed when it is written to <<pcc>> on execution of an <<SRET_CHERI>> instruction.
The handling of <<sepcc>> is otherwise identical to <<mepcc>>, but in supervisor mode.

.Supervisor exception program counter capability register
include::img/sepccreg.edn[]

[#stidc,reftext="stidc"]
==== Supervisor Thread Identifier Capability (stidc)

The <<stidc>> register is used to identify the current software thread in supervisor mode, using the method defined in the section for the unprivileged utidc CSR.
On reset the {ctag} of <<stidc>> will be set to zero and the remainder of the data is UNSPECIFIED.

.Supervisor thread identifier capability register
include::img/stidcreg.edn[]

=== Supervisor-Level CSRs modified by {cheri_priv_s_ext}
==== Supervisor Cause Register (scause)

{cheri_base_ext_name} adds a new exception code for CHERI exceptions that <<scause>> must be able to represent.
The new exception code is listed in xref:scauses[xrefstyle=short].
The behavior and usage of <<scause>> otherwise remains as described in xref:scause[xrefstyle=short].

See <<cheri-mcause>> for the new exceptions priorities when {cheri_base_ext_name} is implemented.

[[stval-cheri]]
==== Supervisor Trap Value Register (stval)

<<stval>> is updated following the same rules as <<mtval-cheri>> for CHERI exceptions
and <<cheri_pte_fault,CHERI page faults>> which are delegated to HS-mode or S-mode.

==== "Smstateen/Ssstateen" Integration
The TID (thread ID) bit in `sstateen0` controls access to the <<utidc>> CSR.
See <<utidc>> for a description of the usage.

.Supervisor State Enable 0 Register (`sstateen0`)
[wavedrom, ,svg]
....
{reg: [
{bits: 1, name: 'C'},
{bits: 1, name: 'FCSR'},
{bits: 1, name: 'JVT'},
{bits: 1, name: 'TID'},
{bits: 28, name: 'WPRI'}
], config:{bits: 32, lanes: 2, hspace:1024}}
....

[#sec_cheri_exception_handling]
=== CHERI Exception handling

CHERI faults are typically higher priority than standard RISC-V faults. E.g., CHERI faults on the <<pcc>> are higher priority than any other fault effecting the program counter such as instruction access fault.

NOTE: `auth_cap` is `cs1`, unless in {cheri_int_mode_name} when it is <<ddc>> (if {cheri_default_ext_name} is implemented).

.Valid CHERI exception combination description
[#cheri_exception_combs_descriptions]
[width="100%",options=header,cols="2,1,3,4"]
|=========================================================================================
| Instructions | Xcause | Description | Check
4+| *All instructions have these exception checks first*
| All                                            | {cheri_excep_cause_pc}     | {cheri_excep_name_pc} | <<pcc>> {ctag} is zero
| All                                            | {cheri_excep_cause_pc}     | {cheri_excep_name_pc} | <<pcc>> is sealed
| All                                            | {cheri_excep_cause_pc}     | {cheri_excep_name_pc} | <<pcc>> does not have <<x_perm>>
| All                                            | {cheri_excep_cause_pc}     | {cheri_excep_name_pc} | Any byte of current instruction out of <<pcc>> bounds^1^
| All                                            | {cheri_excep_cause_pc}     | {cheri_excep_name_pc} | <<pcc>> failed any <<section_cap_integrity,integrity>> check.
4+| *CSR/Xret additional exception check*
| CSR*, <<MRET_CHERI>>, <<SRET_CHERI>>           | {cheri_excep_cause_pc}     | {cheri_excep_name_pc} | <<pcc>> does not have <<asr_perm>> when required for CSR access or execution of <<MRET_CHERI>>/<<SRET_CHERI>>
4+| *Load additional exception checks*
| All loads                                      | {cheri_excep_cause_ld}     | {cheri_excep_name_ld} | `auth_cap` {ctag} is zero
| All loads                                      | {cheri_excep_cause_ld}     | {cheri_excep_name_ld} | `auth_cap` is sealed
| All loads                                      | {cheri_excep_cause_ld}     | {cheri_excep_name_ld} | `auth_cap` does not have <<r_perm>>
| All loads                                      | {cheri_excep_cause_ld}     | {cheri_excep_name_ld} | Any byte of load access out of `auth_cap` bounds^1^
| All loads                                      | {cheri_excep_cause_ld}     | {cheri_excep_name_ld} | `auth_cap` failed any <<section_cap_integrity,integrity>> check.
| capability loads                               | 5^2^                       | Load access fault     | Misaligned capability load
4+| *Store/atomic/cache-block-operation additional exception checks*
| All stores, all atomics, all CBOs              | {cheri_excep_cause_st}     | {cheri_excep_name_st} | `auth_cap` {ctag} is zero
| All stores, all atomics, all CBOs              | {cheri_excep_cause_st}     | {cheri_excep_name_st} | `auth_cap` is sealed
| All atomics, CBO.INVAL*                        | {cheri_excep_cause_st}     | {cheri_excep_name_st} | `auth_cap` does not have <<r_perm>>
| All stores, all atomics, CBO.INVAL*, CBO.ZERO* | {cheri_excep_cause_st}     | {cheri_excep_name_st} | `auth_cap` does not have <<w_perm>>
| CBO.CLEAN*, CBO.FLUSH*                         | {cheri_excep_cause_st}     | {cheri_excep_name_st} | `auth_cap` does not have both <<r_perm>> and <<w_perm>>
| All stores, all atomics                        | {cheri_excep_cause_st}     | {cheri_excep_name_st} | any byte of access out of `auth_cap` bounds^1^
| CBO.ZERO*, CBO.INVAL*                          | {cheri_excep_cause_st}     | {cheri_excep_name_st} | any byte of cache block out of `auth_cap` bounds^1^
| CBO.CLEAN*, CBO.FLUSH*                         | {cheri_excep_cause_st}     | {cheri_excep_name_st} | all bytes of cache block out of `auth_cap` bounds^1^
| CBO.INVAL*                                     | {cheri_excep_cause_st}     | {cheri_excep_name_st} | <<pcc>> does not have <<asr_perm>>
| All stores, all atomics, all CBOs              | {cheri_excep_cause_st}     | {cheri_excep_name_st} | `auth_cap` failed any <<section_cap_integrity,integrity>> check.
| Capability stores                              | 7^2^                       | Store access fault    | Misaligned capability store
|=========================================================================================

^1^ The bounds checks include the cases where the bounds could not be decoded.

^2^ Misaligned capability accesses raise access faults instead of misaligned faults since they cannot be emulated in software.

NOTE: <<CBO_ZERO_CHERI>> is performed as a cache block wide store.  All
CMOs operate on the cache block which contains the address.  Prefetch instructions check
that the authorizing capability is has its {ctag} set, is not sealed, has the required permission (<<r_perm>>,
<<w_perm>>, <<x_perm>>) corresponding to the instruction, and has bounds which
include at least one byte of the cache block; if any check fails, the prefetch
is not performed but no exception is generated.

[#CHERI_SPEC,reftext="CHERI Exceptions and speculative execution"]
=== CHERI Exceptions and speculative execution

#should be non-normative - and needs more details - move to appendix?#

CHERI adds architectural guarantees that can prove to be microarchitecturally useful.
Speculative-execution attacks can -- among other factors -- rely on instructions that fail CHERI permission checks not to take effect.
When implementing any of the extensions proposed here, microarchitects need to carefully consider the interaction of late-exception raising and side-channel attacks.

[#section_pma]
=== Physical Memory Attributes (PMA)

Typically, only parts of the entire memory space need to support CHERI {ctag}s.
Therefore, it is desirable that harts supporting {cheri_base_ext_name} extend PMAs with Physical Memory Attributes indicating whether a memory region allows storing CHERI {ctag}s.
If they are not supported, then what the behavior is when attempting to access them.

There are three levels of support:

.CHERI PMAs
[#cheri_pmas]
[width="100%",options=header]
|=========================================================================================
| PMA                          | Load Behavior    | Store Behavior                      | Comment
| _CHERI {ctag_title}_       | Load {ctag}      | Store {ctag}                        | Tagged memory supporting {ctag}s
| _CHERI {ctag_title} Strip_ | Load zero {ctag} | Ignore stored {ctag}                | No support for {ctag}s, ignore them
| _CHERI {ctag_title} Fault_ | Load zero {ctag} | Store/AMO Access Fault on {ctag}^1^ | No support for {ctag}s, trap on storing one
|=========================================================================================

^1^ The access fault is triggered on all capability stores or atomics such as <<SC>> or <<AMOSWAP_C>> when <<c_perm>> and <<w_perm>> are granted and the {ctag} is set to one.

Memory regions that do not have the _CHERI {ctag_title}_ PMA do not require storage for {ctag}s.

[#section_vm]
=== Virtual Memory

CHERI checks are made on the effective address according to the current translation scheme.
I.e., on the virtual address if translation is enabled or the physical address if translation is disabled.

Implicit memory accesses made by the page table walker are not subject to CHERI checks.

NOTE: A future extension may add CHERI checks to the page table walker.

[#section_cheri_disable]
== "{cheri_priv_m_reg_enable_ext}" Extension, Version 1.0

ifdef::cheri_v9_annotations[]
NOTE: *CHERI v9 Note:* This feature is new and different from CHERI v9's
per-privilege enable bits.

NOTE: *CHERI v9 Note:* The rules for excepting have been tightened here. Also,
it is not possible to disable CHERI checks completely.
endif::[]

CAUTION: #ARC-QUESTION: The CBZE, CBIE etc. bits are specified by Zicbo*, can this be defined by {cheri_priv_m_ext}/{cheri_priv_s_ext}+{cheri_default_ext_name} instead of adding a new priv extension?#

When using a system with {cheri_default_ext_name}, it may be desirable to disabling CHERI register and instruction access to some (or all) privilege levels such that they operate as a RV32I/RV64I system without any observable presence of CHERI features.
{cheri_priv_m_reg_enable_ext} includes functions to disable explicit access to CHERI
registers and instructions.
The {cheri_priv_m_reg_enable_ext} extension makes the `CRE` bit of <<mseccfg>>, <<menvcfg>>, and <<senvcfg>> writable.

IMPORTANT: If {cheri_base_ext_name} is supported and {cheri_default_ext_name} is not supported, then {cheri_priv_m_reg_enable_ext} must also not be supported.
In this case all CRE bits are hardwired to 1 and access to CHERI registers is always permitted.
This allows implementing a hart that always runs in {cheri_cap_mode_name}.

CHERI register access is disabled if

* XLEN in the current mode is less than MXLEN, or
* the endianness in the current mode is not the reset value of <<mstatus_cheri>>.MBE, or
* the effective CRE for the current privilege is 0.

The effective CRE for the current privilege is:

* Machine: `<<mseccfg>>.CRE`
* Supervisor: `<<mseccfg>>.CRE & <<menvcfg>>.CRE`
* User: `<<mseccfg>>.CRE & <<menvcfg>>.CRE & <<senvcfg>>.CRE`

NOTE: The effective CRE is always 1 in debug mode.

NOTE: On reset CHERI register access is disabled (<<mseccfg>>.CRE resets to zero).

The following occurs when executing code in a privilege mode that has CHERI register access disabled:

* Instructions that access full capability registers instead of only the XLEN subset (implicitly or explicitly) cause illegal instruction exceptions
+
NOTE: The only instruction added by {cheri_base_ext_name} that does not access capability state is <<CRAM>>, all others are disabled.
* Executing CSR instructions accessing any CSR added by any CHERI extension ({cheri_default_ext_name}, {cheri_priv_m_ext}, {cheri_priv_s_ext}, {cheri_priv_h_ext}) causes an illegal instruction exception
* Executing CSR instructions accessing any CSR extended to YLEN only allows XLEN access.
* All allowed instructions execute as if the CHERI execution mode is {cheri_int_mode_name}.
// FIXME: there should be no way to observe the M bit, do we need to mentions this?
// The mode bit in <<pcc>> is treated as if it was zero while CHERI register access is disabled.

Disabling CHERI register access has no effect on implicit accesses or security checks.
The last capability written to <<pcc>> and <<ddc>> before disabling CHERI register access will be used to authorize instruction execution and data memory accesses.

[NOTE]
====
Disabling CHERI register access prevents low-privileged {cheri_int_mode_name} software
from interfering with the correct operation of higher-privileged {cheri_int_mode_name} software
that do not perform <<ddc>> switches on trap entry and return.

Disabling CHERI register access allows harts supporting CHERI to be fully
compatible with standard RISC-V, so CHERI instructions, such as <<CRAM>>, that
do not change the state of CHERI CSRs raise exceptions when CRE=0.
This is the default behavior on reset.
====

xref:cheri_behavior_cre_mode[xrefstyle=short] summarizes the behavior of a hart
in connection with the <<section_cheri_disable,CRE>> and the <<cheri_execution_mode>> while in a privilege other than debug mode.

.Hart's behavior depending on the effective <<section_cheri_disable,CRE>> and <<cheri_execution_mode>>
[#cheri_behavior_cre_mode,width=100%,options=header,align=center,%autowidth,cols="40,20,20,20"]
|==============================================================================
| | CRE=0, M-bit=X^1^ | CRE=1, M-bit={int_mode_value} | CRE=1, M-bit={cap_mode_value}
| Authorizing capability for memory accesses | <<ddc>> or <<pcc>> | <<ddc>> or <<pcc>> | Instruction's capability operand
| New CHERI CSR Access Width                | ✘                 | YLEN                  | YLEN
| Extended CHERI CSR Access Width      | XLEN              | XLEN                  | YLEN
| CHERI Instructions Allowed           | ✘                 | ✔                    | ✔
| Compressed Instructions Remapped     | No                | No                    | Yes^2^
| Summary                              | **_Fully RISC-V compatible_**^3^ | **{cheri_int_mode_name}** | **{cheri_cap_mode_name}**
|==============================================================================

^1^ M-bit is irrelevant when CRE=0. +
^2^ See xref:legacy_mnemonics[xrefstyle=short] for a list of remapped
instructions. +
^3^ The hart is fully compatible with standard RISC-V when CRE=0 provided that <<pcc>>, <<mtvecc>>, <<mepcc>>, <<stvecc>>, <<sepcc>>, <<vstvecc>>, <<vsepcc>> and <<ddc>> have not been changed from the default reset state (i.e., hold the <<infinite-cap>> capability).


[#section_cheri_dyn_xlen]
== "{cheri_priv_m_dyn_xlen_ext}" Extension, Version 1.0

{cheri_priv_m_dyn_xlen_ext} eliminates some restrictions for SXL and UXL imposed in {cheri_priv_m_ext} to allow implementations supporting multiple base ISAs.
This extension allows the SXL, UXL, MBE, SBE, and UBE fields of <<mstatus_cheri>> to be writable (which is prohibited by {cheri_priv_m_ext} otherwise).

CAUTION: #ARC-QUESTION: Should this extension be folded into the {cheri_priv_m_reg_enable_ext} extension?#

Changing XLEN::
Setting the SXL or UXL field to a value that is not MXLEN disables most CHERI features and instructions, as described in xref:section_cheri_disable[xrefstyle=short], while in that privilege mode.
+
NOTE: If CHERI register access must be disabled in a mode for security reasons, software should set CRE to 0 regardless of the SXL and UXL fields.
+
Whenever XLEN in any mode is set to a value less than MXLEN, standard RISC-V rules are followed.
This means that all operations must ignore source operand register bits above the configured XLEN, and must sign-extend results to fill all MXLEN bits in the destination register.
Similarly, *pc* bits above XLEN are ignored, and when the *pc* is written, it is sign-extended to fill MXLEN.
The integer writing rule from CHERI is followed, so that every register write also zeroes the metadata and {ctag} of the
destination register.
+
However, CHERI operations and security checks will continue using the entire hardware register (i.e., YLEN bits) to correctly decode capability bounds.

Changing endianness::
Setting the MBE, SBE, or UBE field to a value that is not the reset value of MBE disables most CHERI features and instructions, as described in xref:section_cheri_disable[xrefstyle=short], while in that privilege mode.


[#section_priv_cheri_vmem]
== "{cheri_priv_vmem_ext}" Extension, Version 1.0 for {cheri_base64_ext_name}

RISC-V's page-based virtual-memory management is generally orthogonal to CHERI.
In {cheri_base_ext_name}, capability addresses are interpreted with respect to the privilege level of the processor in line with RISC-V's handling of integer addresses.
In machine mode, capability addresses are generally interpreted as physical addresses; if the <<mstatus_cheri>> MPRV flag is asserted, then data accesses (but not instruction accesses) will be interpreted as if performed by the privilege mode in <<mstatus_cheri>>'s MPP.
In supervisor and user modes, capability addresses are interpreted as dictated by the current *satp* configuration: addresses are virtual if paging is enabled and physical if not.

{cheri_priv_vmem_ext} requires that the <<pcc>> grants the <<asr_perm>> to change the page-table root *satp* and other virtual-memory parameters as described in xref:supervisor-level-csrs-section[xrefstyle=short].

[#section_cw_bit]
=== Capability Write (CW) Bit

{cheri_priv_vmem_ext} defines the Capability Write (CW) bit in Page Table Entries (PTEs) for Sv39, Sv48, and Sv57 virtual memory systems on {cheri_base64_ext_name} harts. The CW bit controls whether capabilities with their {ctag} set can be written to a virtual page.

NOTE: _Sv32_ does not have any spare PTE bits, and so this bit does not exist for RV32.

IMPORTANT: Any hart that supports {cheri_base_ext_name} and at least one of the Sv39, Sv48, and Sv57 virtual memory translation schemes must also implement {cheri_priv_vmem_ext}.

[#limit_cap_prop]
==== Limiting Capability Propagation

CAUTION: #ARC-QUESTION: Is this too much rationale? Should it be trimmed down and just describe the mechanism?#

Page table enforcement can allow the operating system to limit the flow of capabilities between processes.
It is highly desirable that a process should only possess capabilities that have been issued for that address space by the operating system.
Unix processes may share memory for efficient communication, but capability pointers must not be shared across these channels into a foreign address space.
An operating system might defend against this by only issuing a capability to the shared region that does not grant the load/store capability permission.
However, there are circumstances where portions of general-purpose, mmapped^*^ memory become shared, and the operating system must prevent future capability communication through those pages.
This is not possible without restructuring software, as the capability for the original allocation, which spans both shared memory and private memory, would need to be deleted and replaced with a list of distinct capabilities with appropriate permissions for each range.
Such a change would not be transparent to the program.
Such sharing through virtual memory is on the page granularity, so preventing capability writes with a PTE permission is a natural solution.

^*^ _allocated using mmap_

[#cheri_pte_fault]
=== CHERI page faults

CHERI adds the concept of _CHERI page faults_. They are split into :

* {cheri_excep_name_pte_ld} (cause value {cheri_excep_cause_pte_ld}), and
* {cheri_excep_name_pte_st} (cause value {cheri_excep_cause_pte_st})

All {cheri_base64_ext_name} harts with virtual memory must implement {cheri_priv_vmem_ext} and so can raise _{cheri_excep_name_pte_st}_ exceptions.
Only harts which also implement a revocation scheme such as {cheri_priv_crg_ext} can raise _{cheri_excep_name_pte_ld}_ exceptions.

==== Extending the Page Table Entry Format

The page table entry format remains unchanged for Sv32.
However, a new bit, Capability Write (CW), is added to leaf PTEs in Sv39, Sv48 and Sv57 as shown in xref:sv39pte_cw[xrefstyle=short], xref:sv48pte_cw[xrefstyle=short] and xref:sv57pte_cw[xrefstyle=short] respectively.
For non-leaf PTEs this bit remains reserved and must be cleared by software for forward compatibility, or else a page-fault exception is raised.
Additionally, if the hypervisor extension is enabled this bit remains reserved for leaf and non-leaf PTEs used in guest address translation.

CAUTION: #ARC-QUESTION: The current bit 60 has been allocated by Svrsw60t59b, should we use bit 58?#

.Sv39 page table entry
[#sv39pte_cw]
include::img/sv39pte_cw.edn[]

.Sv48 page table entry
[#sv48pte_cw]
include::img/sv48pte_cw.edn[]

.Sv57 page table entry
[#sv57pte_cw]
include::img/sv57pte_cw.edn[]

The CW bit indicates whether reading or writing capabilities with the {ctag} set to the virtual page is permitted.
When the CW bit is set, capabilities are written as usual.

If the CW bit is clear then:

* When a capability load or AMO instruction is executed, the implementation clears the {ctag} bit of the capability read from the virtual page.
* A <<cheri_pte_fault,_{cheri_excep_name_pte_st}_>> exception is raised when a capability store or AMO instruction is executed and the {ctag} bit of the capability being written is set.

[[pte_cw_summary]]
.Summary of memory access behavior depending on CW in the PTEs
[%autowidth,float="center",align="center",cols="<,<,<",options="header"]
|===
|PTE.CW |Instruction          | Behavior
| 0     |Capability load      | Set loaded {ctag} to zero
| 0     |Capability store/AMO | Raise a _{cheri_excep_name_pte_st}_ if the stored {ctag} is set
| 1     |Any                  | Normal operation
|===

[NOTE]
====
The {ctag} bit of the stored capability is checked _after_ it is potentially cleared due to missing permissions.
Therefore, the behavior in this section isn't relevant if:

* The authorizing capability doesn't have <<c_perm>>.
* Insufficient <<sl_perm>> has cleared the {ctag} of the to-be-stored capability.
====

[#section_invalid_addr_conv,reftext="Invalid address conversion"]
=== Invalid Address Handling

When address translation is in effect and MXLEN=64, the upper bits of virtual
memory addresses must match for the address to be valid.

The CSRs shown in xref:CSR_exevectors[xrefstyle=short], as well as the pc, need not hold all possible invalid addresses.
Implementations may convert an invalid address into some other invalid address that the register is capable of holding.

However, the bounds encoding of capabilities depends on the address value if the bounds are not of the <<infinite-cap>> capability.

Therefore implementations must not convert invalid addresses to other arbitrary invalid addresses in an unrestricted manner if the bounds are not <<infinite-cap>>.

If the bounds could not be decoded due to the address being invalid, and the bounds not being <<infinite-cap>>, then a _{cheri_excep_name_pc}_, _{cheri_excep_name_ld}_ or _{cheri_excep_name_st}_ exception is raised as appropriate.

NOTE: In all cases, if the authorizing capability has <<infinite-cap>> bounds, then the behavior is identical to the normal RISC-V behavior without CHERI.

NOTE: Not requiring to the implementation to decode the bounds for invalid addresses reduces the size of bounds comparators from 64-bits to the supported virtual address width.

==== Updating CSRs

A CSR may be updated to hold a capability with an invalid address, due to:

* executing instructions, such as <<CSRRW_CHERI>>
* hardware updates to CSRs such as storing the <<pcc>> into  <<mepcc>>/<<sepcc>> etc. when taking an exception.

To ensure that the bounds of a valid capability cannot be corrupted:

* If the new address is invalid and the capability does not have <<infinite-cap>> bounds, then set the {ctag} to zero before writing to the CSR.

NOTE: When the capability's address is invalid and happens to match an invalid address which the CSR
can hold, then it is implementation defined whether to set the {ctag} to zero.

==== Branches and Jumps

If the effective target address of the jump or branch is invalid, and the authorizing capability does not have <<infinite-cap>> bounds, then set the {ctag} of the target <<pcc>> to zero.
This will cause a {cheri_excep_name_pc} exception when executing the target instruction.

NOTE: RISC-V harts that do not support {cheri_base_ext_name} normally raise an
instruction access fault or page fault after jumping or branching to an invalid address.
Therefore, {cheri_base_ext_name} aims to preserve that behavior to ensure that
harts supporting {cheri_base_ext_name} and {cheri_default_ext_name} are fully
compatible with RISC-V harts provided that <<pcc>> and <<ddc>> are set to the
<<infinite-cap>> capability.

==== Memory Accesses

If the effective address of the memory access is invalid, and the authorizing capability does not have <<infinite-cap>> bounds, then raise a {cheri_excep_name_ld} or {cheri_excep_name_st} exception because the bounds cannot be reliably decoded.

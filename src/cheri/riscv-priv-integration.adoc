[#section_priv_cheri]
== "{cheri_priv_m_ext}/{cheri_priv_s_ext}" Extensions, Version 1.0

ifdef::cheri_standalone_spec[]
WARNING: This chapter will appear in the priv spec. Exact location TBD.
endif::[]

This chapter describes integration of {cheri_base_ext_name} with the RISC-V privileged architecture.

=== Machine-Level CSRs added or extended by {cheri_priv_m_ext}

{cheri_base_ext_name} extends some M-mode CSRs to hold capabilities or
otherwise add new functions. <<asr_perm>> in the <<pcc>> is typically required for access
to the CSRs.

[#mtvecc,reftext="mtvecc"]
==== Machine Trap Vector Base Address Capability Register (mtvecc)

The <<mtvecc>> register extends <<mtvec>> to hold a code capability.
Its reset value is nominally the <<infinite-cap>> capability.

NOTE: <<mtvecc>> exists in all CHERI implementations, and so may be used as a source of the <<infinite-cap>> capability after reset.

.Machine-mode trap-vector base-capability register
include::img/mtveccreg.edn[]

The fields in the metadata are WARL as many fields can be implemented as constants.

NOTE: Examples of WARL behavior include always setting <<x_perm>> to 1 and setting the reserved fields to zero, otherwise the capability is unusable.
 Another example is to partially or fully restrict the bounds to constant values.

NOTE: Care must be taken however that an <<infinite-cap>> capability is available to software after reset if this CSR does not represent one.

When traps are taken into machine mode, the pc is updated following the standard `mtvec` behavior.
The valid tag and metadata from <<mtvecc>> are also written to the <<pcc>>.

Following the standard `mtvec` behavior, the value of `mtvecc.address` can be viewed with a range of different addresses:

. The MODE field is included in `mtvecc.address[1:0]` but it does not form part of the trap vector address.
. When MODE=Vectored, the trap vector address is incremented by four times the interrupt number.
. CSR reads include MODE in `mtvecc.address[1:0]`.

`HICAUSE` is defined to be the largest interrupt cause value that the implementation can write
to `Xcause` when an interrupt is taken.

Therefore the minimum observable address is `mtvecc.address & ~3` and the maximum is `(mtvecc.address & ~3) + 4 x HICAUSE`.

All possible observable values must be in the <<section_cap_representable_check>>.
Software must ensure this is true when writing to <<mtvecc>>, and the hardware sets the valid tag to zero if any values are out of the <<section_cap_representable_check>>.

NOTE: Modifying the address of any capability outside of the <<section_cap_representable_check>> without clearing the valid tag causes a security hole as the interpretation of the bounds changes.
Therefore requiring that all possible observable addresses are representable but not necessary in bounds is the minimum security requirement.

<<mtvecc>> is always updated using <<SCADDR>> semantics and so writing a sealed capability will cause the valid tag to be set to zero.

NOTE: The capability in <<mtvecc>> is _not_ unsealed when it is written to <<pcc>>, unlike other executing from other CSRs such as <<mepcc>>.

<<mtvecc>> follows the rule from `mtvec` about not needing to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).

[#mscratchc, reftext="mscratchc"]
==== Machine Scratch Capability Register (mscratchc)

The <<mscratchc>> register extends <<mscratch>> to hold a capability.

{TAG_RESET_MCSR}

It is not WARL, all capability fields must be implemented.

.Machine-mode scratch capability register
include::img/mscratchcreg.edn[]

[#mepcc,reftext="mepcc"]
==== Machine Exception Program Counter Capability (mepcc)

The <<mepcc>> register extends <<mepc>> to hold a capability.
Its reset value is nominally the <<infinite-cap>> capability.

.Machine exception program counter capability register
include::img/mepccreg.edn[]

`mepcc.address` is the `mepc` CSR, and so the follows the standard rules meaning that:

.  `mepcc.address[0]=0`, and
.  `mepcc.address[1]=0` when IALIGN is fixed to 32
.  `mepcc.address[1]` reads as zero when IALIGN is programmable and is set to 32

As listed above for <<mtvecc>>, this means that `mepcc.address` can represent multiple different values.
Therefore software must ensure that all possible values are in the <<section_cap_representable_check>> on writing, otherwise the hardware sets the written valid tag to zero.

Sealed capabilities may be written to <<mepcc>>.
The valid tag is set to zero on writing if:

.  `mepcc.address[0]=1`, or
.  `mepcc.address[1]=1` when IALIGN=32

In the following case the value of the valid tag observable in the CSR depends on the value of IALIGN:

. <<mepcc>> is sealed, the valid tag is set, and
. `mepcc.address[1]=1` and IALIGN=16 when writing the CSR

The valid tag is zero then IALIGN=32 when reading the CSR, or executing <<MRET_CHERI>>, and the valid tag is one when IALIGN=16.

When a trap is taken into M-mode, the pc is written to `mepcc.address` following the standard behavior.
The valid tag and metadata of the <<pcc>> are also written to <<mepcc>>.

The capability in <<mepcc>> is unsealed when it is written to <<pcc>> on execution of an <<MRET_CHERI>> instruction.

<<mepcc>> follows the rule from `mepc` about not needing to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).

[#mtidc,reftext="mtidc"]
==== Machine Thread Identifier Capability (mtidc)

The <<mtidc>> register is used to identify the current software thread in machine mode, using the method defined in the section for the unprivileged <<utidc>> CSR.
On reset the valid tag of <<mtidc>> will be set to zero and the remainder
of the data is UNSPECIFIED.

.Machine thread identifier capability register
include::img/mtidcreg.edn[]

=== Machine-Level CSRs modified by {cheri_priv_m_ext}

[#mstatus_cheri]
==== Machine Status Registers (mstatus and mstatush)

The *mstatus* and *mstatush* registers operate as described in
<<mstatus_cheri>> with two restrictions:

* The <<xlen-control, SXL and UXL>> fields that control the
value of XLEN for S-mode and U-mode must be read-only in implementations supporting {cheri_base_ext_name}.
  Only 1 and 2 are supported values for SXL and UXL

* The <<endianness-control,MBE, SBE, and UBE>> fields that control the memory system endianness for M-mode, S-mode, and U-mode must be read-only in implementations supporting {cheri_base_ext_name}.
   SBE and UBE must be read only and equal to MBE, if S-mode or
U-mode, respectively, is implemented, or read-only zero otherwise.

Changing XLEN or endianness would change the interpretation of all in-memory capabilities, so allowing these fields to change at runtime is prohibited.

NOTE: These restrictions are relaxed if a further privileged CHERI extension, {cheri_priv_m_dyn_xlen_ext}, optionally makes SXL,
UXL, MBE, SBE, and UBE writeable, to support CHERI on implementations that support dynamic XLEN or endianness changes.

CAUTION:: #ARC-QUESTION: Does {cheri_priv_m_dyn_xlen_ext} need to be a separate extension or just a "if xME,xXL bits are writable, then this behavior is followed" note in {cheri_priv_m_ext}#

<<mstatus_cheri>>.MXR has no effect on the CHERI permission checking.

NOTE: CHERI does not need to make use execute only memory for security reasons, and so MXR has no relevance.
 Additionally the 32-bit encoding format does not allow <<x_perm>> to be encoded without <<r_perm>>.

[[cheri-mcause]]
==== Machine Cause Register (mcause)

{cheri_base_ext_name} adds a new exception code for CHERI exceptions that <<mcause>> must be able to represent.
The new exception code and its priority are listed in xref:mcauses[xrefstyle=short] and xref:exception-priority[xrefstyle=short] respectively.
The behavior and usage of <<mcause>> otherwise remains as described in xref:mcause[xrefstyle=short].

WARNING: The current specification uses the CHERI ISAv9 mcause value of {cheri_excep_mcause}, which is designated for custom extensions.

CAUTION:: #ARC-QUESTION: The exact code as well as the mechanism to report subcodes needs to be finalized: https://github.com/riscv/riscv-cheri/issues/536#

#This table needs to be merged with the main table once we've resolve the Xcause type#

[[exception-priority-cheri]]
.Synchronous exception priority in decreasing priority order. Entries added in {cheri_base_ext_name} are in *bold*
[float="center",align="center",cols="<1,>1,<8",options="header"]
|===
|Priority |Exc.Code |Description
|_Highest_ |3 |Instruction address breakpoint
| .>|*{cheri_excep_mcause}* .<|*Prior to instruction address translation:* +
*CHERI fault due to PCC checks (tag, execute permission, invalid address and bounds^1^)*
| .>|12, 1 .<|During instruction address translation: +
First encountered page fault or access fault
| .>|1 .<|With physical address for instruction: +
Instruction access fault

| .>|2 +
0 +
8,9,11 +
3 +
3 .<|Illegal instruction +
Instruction address misaligned +
Environment call +
Environment break +
Load/store/AMO address breakpoint

| .>| *{cheri_excep_mcause}* .<| *CHERI faults due to:* +
*PCC <<asr_perm>> clear* +
*Branch/jump target address checks (tag, execute permissions, invalid address and bounds)*

| .>|*{cheri_excep_mcause}* .<|*Prior to address translation for an explicit memory access:* +
*CHERI fault due to capability checks (tag, sealed, permissions, invalid address and bounds)*
| .>|4,6 .<|*Load/store/AMO capability address misaligned* +
Optionally: +
Load/store/AMO address misaligned
| .>|13, 15, 5, 7 .<|During address translation for an explicit memory access: +
First encountered *<<section_priv_cheri_vmem,CHERI PTE page fault>>*^23^, page fault or access fault
| .>|5,7 .<|With physical address for an explicit memory access: +
Load/store/AMO access fault
| .>|4,6 .<|If not higher priority: +
Load/store/AMO address misaligned
.>|_Lowest_ .>|13 .<|*If not higher priority: +
CHERI load PTE page fault^4^*
|===

^1^ PCC bounds are checked against all bytes of fetched instructions.
 If the instructions cannot be decoded to determine the length, then the <<pcc>> bounds check is made against the minimum sized instruction supported by the implementation which can be executed, when prioritizing against Instruction Access Faults.

^2^ The higher priority <<section_priv_cheri_vmem,CHERI PTE page fault>> covers capability loads or atomics where the loaded valid tag _is not_ checked, and all capability stores and atomics where the stored valid tag is set.

^3^ <<section_priv_cheri_vmem,CHERI PTE page fault>> exceptions have the same priority against access faults as normal RISC-V page faults. If a normal RISC-V page fault _and_ a <<section_priv_cheri_vmem,CHERI PTE page fault>> are both detected simultaneously, then both are recorded as shown in <<mtval2-page-fault>>.

^4^ The lower priority <<section_priv_cheri_vmem,CHERI PTE page fault>> only covers capability loads and atomics where the loaded valid tag _is_ checked.

NOTE: The full details of the CHERI exceptions with cause value {cheri_excep_mcause} are in xref:cheri_exception_combs_descriptions[xrefstyle=short].

==== Machine Trap Delegation Register (medeleg)

Bit {cheri_excep_mcause} of <<medeleg>> now refers to a valid exception and so can be used to
delegate CHERI exceptions to supervisor mode.

[[mtval-cheri]]
==== Machine Trap Value Register (mtval)

ifdef::cheri_v9_annotations[]
WARNING: *CHERI v9 Note:* Encoding and values changed, and generally were
simplified.
endif::[]

The <<mtval>> register is an MXLEN-bit read-write register formatted as shown
in xref:mtval-format[xrefstyle=short]. When a data memory access causes
a CHERI fault taken into M-mode, <<mtval>> is written with the
MXLEN-bit effective address which caused the fault according to the existing
rules for reporting load/store addresses. In this case
the TYPE field of <<mtval2>> shown in xref:mtval2-cheri-type[xrefstyle=short] is
set to {cheri_excep_type_data}. For all other CHERI faults <<mtval>> is set to zero.

The behavior of <<mtval>> is otherwise as described in xref:mtval[xrefstyle=short].

If the hardware platform specifies that no exceptions set <<mtval>> to a
non-zero value, then <<mtval>> is read-only zero for all CHERI exceptions.

.Machine trap value register
[#mtval-format]
include::img/mtvalreg.edn[]

[#mtval2,reftext="mtval2"]
==== Machine Trap Value Register 2 (mtval2)

ifdef::cheri_v9_annotations[]
WARNING: *CHERI v9 Note:* This CSR was not part of CHERIv9.
endif::[]

The <<mtval2>> register is required for CHERI machine mode.

When a CHERI fault, or <<section_priv_cheri_vmem,CHERI PTE page fault>>, is taken into M-mode, <<mtval2>> is written
with additional CHERI-specific exception information with the format shown in
xref:mtval2-format[xrefstyle=short] to assist software in handling the trap.

If <<mtval>> is read-only zero for CHERI exceptions then <<mtval2>> is also read-only zero
for CHERI exceptions.

===== mtval2 values for CHERI faults

.Machine trap value register 2 format for CHERI Faults
[#mtval2-format]
include::img/mtval2reg.edn[]

NOTE: <<mtval2>> is also used for Hypervisor guest physical addresses, and so the implemented bits must also cover that use case.
 If the H extension is not implemented then all WPRI fields in <<mtval2-format>> are read-only-zero.

TYPE is a CHERI-specific fault type that caused the exception while CAUSE
is the cause of the fault. The possible CHERI types and causes are encoded as
shown in xref:mtval2-cheri-type[xrefstyle=short] and
xref:mtval2-cheri-causes[xrefstyle=short] respectively.

.Encoding of TYPE field for CHERI Faults
[#mtval2-cheri-type,width=65%,float="center",align="center",options=header,cols="30%,70%"]
|==============================================================================
| CHERI Type Code           | Description
| {cheri_excep_type_pcc}    | CHERI instruction fetch fault
| {cheri_excep_type_data}   | CHERI data fault due to load, store or AMO
| 3-15                      | Reserved
|==============================================================================

#ARC note: we plan to merge invalid addresses and bounds faults - giving 4 types (riscv-cheri issue #601)#

.Encoding of CAUSE field
[#mtval2-cheri-causes,width=55%,float="center",align="center",options=header]
|==============================================================================
| CHERI Cause Code              | Description
| {cheri_excep_cause_tag}       | Valid tag violation
| {cheri_excep_cause_seal}      | Seal violation
| {cheri_excep_cause_perm}      | Permission violation
| {cheri_excep_cause_inv_addr}  | Invalid address violation
| {cheri_excep_cause_bounds}    | Bounds violation
| 5-15                          | Reserved
|==============================================================================

CHERI violations have the following priority order:

. Valid tag violation (_Highest_)
. Seal violation
. Permission violation
. Invalid address violation
. Bounds violation (_Lowest_)

===== mtval2 values for Load/Store/AMO Page Faults

Page faults can be caused by normal RISC-V page faults and also by CHERI <<section_priv_cheri_vmem,PTE>> faults.
If both are detected at once, then both are recorded.

.mtval2 for page faults
[#mtval2-page-fault,width=70%,float="center",align="center",cols="2,1",options=header]
|==============================================================================
| Fault                                                        | Value
| RISC-V page fault                                            | 0
| <<section_priv_cheri_vmem,CHERI PTE page fault>>                       | 1
| RISC-V page fault and <<section_priv_cheri_vmem,CHERI PTE page fault>> | 2
|==============================================================================

NOTE: Reporting both allows the software the choice about which action to take first, for example a write to a
 page with no write permission, _and_ the incorrect value of <<section_cheri_priv_crg_ext,PTE.CRG>> requires two actions.
 Software can then decide whether to prioritize the copy-on-write procedure to fix the lack of write
 permission, or to sweep the page.

==== "Smstateen/Ssstateen" Integration
The TID bit in `mstateen0` controls access to the <<stidc>> CSR.

.Machine State Enable 0 Register (`mstateen0`)
[wavedrom, ,svg]
....
{reg: [
{bits: 1, name: 'C'},
{bits: 1, name: 'FCSR'},
{bits: 1, name: 'JVT'},
{bits: 1, name: 'TID'},
{bits: 52, name: 'WPRI'},
{bits: 1, name: 'P1P13'},
{bits: 1, name: 'CONTEXT'},
{bits: 1, name: 'IMSIC'},
{bits: 1, name: 'AIA'},
{bits: 1, name: 'CSRIND'},
{bits: 1, name: 'WPRI'},
{bits: 1, name: 'ENVCFG'},
{bits: 1, name: 'SE0'},
], config: {bits: 64, lanes: 4, hspace:1024}}
....


[#supervisor-level-csrs-section]
=== Supervisor-Level CSRs added or extended by {cheri_priv_s_ext}

{cheri_base_ext_name} extends some of the existing RISC-V CSRs to be able to
hold capabilities or with other new functions. <<asr_perm>> in the <<pcc>> is typically required for access to these CSRs.

[#stvecc,reftext="stvecc"]
==== Supervisor Trap Vector Base Address Capability Register (stvecc)

The <<stvecc>> register extends <<stvec>> that is able to hold a capability.
When the S-mode execution environment starts, the value is nominally the <<infinite-cap>> capability.

.Supervisor trap-vector base-capability register
include::img/stveccreg.edn[]

The handling of <<stvecc>> is otherwise identical to <<mtvecc>>, but in supervisor mode.

[#sscratchc, reftext="sscratchc"]
==== Supervisor Scratch Capability Register (sscratchc)

The <<sscratchc>> register extends <<sscratch>> to hold a capability.

{TAG_RESET_SCSR}

It is not WARL, all capability fields must be implemented.

.Supervisor scratch capability register
include::img/sscratchcreg.edn[]

[#sepcc,reftext="sepcc"]
==== Supervisor Exception Program Counter Capability (sepcc)

The <<sepcc>> register extends <<sepc>> to hold a capability.
Its reset value is the <<infinite-cap>> capability.

As shown in xref:CSR_exevectors[xrefstyle=short], <<sepcc>> is a code capability, so it does not need to be able to hold all possible invalid addresses (see <<section_invalid_addr_conv>>).
Additionally, the capability in <<sepcc>> is unsealed when it is written to <<pcc>> on execution of an <<SRET_CHERI>> instruction.
The handling of <<sepcc>> is otherwise identical to <<mepcc>>, but in supervisor mode.

.Supervisor exception program counter capability register
include::img/sepccreg.edn[]

[#stval2,reftext="stval2"]
==== Supervisor Trap Value Register 2 (stval2)

The <<stval2>> register is an SXLEN-bit read-write register, which is added as
part of {cheri_priv_s_ext} when the implementation supports S-mode. Its CSR
address is 0x14b.

<<stval2>> is updated following the same rules as <<mtval2>> for CHERI exceptions
and <<cheri_pte_fault,CHERI PTE page faults>> which are delegated to HS-mode or S-mode.
It is written to zero by the hardware for all other exceptions, except as listed otherwise by other
future extensions.

NOTE: Unlike <<mtval2>>, <<stval2>> is a new a CSR added by {cheri_priv_s_ext}.

IMPORTANT: #The mechanism to report exception subcodes needs to be finalized: https://github.com/riscv/riscv-cheri/issues/536#

.Supervisor trap value register 2
[#stval2-format]
include::img/stval2reg.edn[]

[#stidc,reftext="stidc"]
==== Supervisor Thread Identifier Capability (stidc)

The <<stidc>> register is used to identify the current software thread in supervisor mode, using the method defined in the section for the unprivileged utidc CSR.
On reset the valid tag of <<stidc>> will be set to zero and the remainder of the data is UNSPECIFIED.

.Supervisor thread identifier capability register
include::img/stidcreg.edn[]

=== Supervisor-Level CSRs modified by {cheri_priv_s_ext}
==== Supervisor Cause Register (scause)

{cheri_base_ext_name} adds a new exception code for CHERI exceptions that <<scause>> must be able to represent.
The new exception code is listed in xref:scauses[xrefstyle=short].
The behavior and usage of <<scause>> otherwise remains as described in xref:scause[xrefstyle=short].

See <<cheri-mcause>> for the new exceptions priorities when {cheri_base_ext_name} is implemented.

[[stval-cheri]]
==== Supervisor Trap Value Register (stval)

<<stval>> is updated following the same rules as <<mtval-cheri>> for CHERI exceptions
and <<cheri_pte_fault,CHERI PTE page faults>> which are delegated to HS-mode or S-mode.

==== "Smstateen/Ssstateen" Integration
The TID (thread ID) bit in `sstateen0` controls access to the <<utidc>> CSR.
See <<utidc>> for a description of the usage.

.Supervisor State Enable 0 Register (`sstateen0`)
[wavedrom, ,svg]
....
{reg: [
{bits: 1, name: 'C'},
{bits: 1, name: 'FCSR'},
{bits: 1, name: 'JVT'},
{bits: 1, name: 'TID'},
{bits: 28, name: 'WPRI'}
], config:{bits: 32, lanes: 2, hspace:1024}}
....

[#sec_cheri_exception_handling]
=== CHERI Exception handling

CAUTION: #ARC-QUESTION: Need feedback whether to add this info to xcause or xtval2: https://github.com/riscv/riscv-cheri/issues/536#

CHERI faults are typically higher priority than standard RISC-V faults. E.g., CHERI faults on the <<pcc>> are higher priority than any other fault effecting the program counter such as instruction access fault.

CHERI faults require additional information to be reported.
The CSRs updated depend on the mode the trap is taken into, as shown in
<<cheri-fault-reporting>>.

The additional information is written for CHERI faults and <<cheri_pte_fault,CHERI PTE page faults>>, and
is otherwise written to zero for all other exceptions, except as listed otherwise by other
future extensions.

.CHERI fault reporting
[#cheri-fault-reporting,width=65%,float="center",align="center",options=header,cols="1,1,1"]
|==============================================================================
| Trap taken into  | Faulting address | Additional CHERI fault information
| M-mode           | <<mtval>>        | <<mtval2>>
| HS-mode / S-mode | <<stval>>        | <<stval2>>
| VS-mode          | <<vstval>>       | <<vstval2>>
|==============================================================================

NOTE: `auth_cap` is <<ddc>> for {cheri_int_mode_name} and `cs1` for {cheri_cap_mode_name}

.Valid CHERI exception combination description
[#cheri_exception_combs_descriptions]
[width="100%",options=header,cols="2,1,1,1,3,4"]
|=========================================================================================
| Instructions | Xcause | Xtval2. TYPE | Xtval2. CAUSE | Description | Check
6+| *All instructions have these exception checks first*
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_tag}      | <<pcc>> valid tag       | not(<<pcc>>.tag)
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_seal}     | <<pcc>> seal            | isCapSealed(<<pcc>>)
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_perm}     | <<pcc>> permission      | not(<<pcc>>.<<x_perm>>)
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_inv_addr} | <<pcc>> invalid address | <<pcc>> holds an invalid address
| All | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_bounds}   | <<pcc>> bounds          | Any byte of current instruction out of <<pcc>> bounds
6+| *CSR/Xret additional exception check*
| CSR*, <<MRET_CHERI>>, <<SRET_CHERI>> | {cheri_excep_mcause} | {cheri_excep_type_pcc} | {cheri_excep_cause_perm}          | <<pcc>> permission | not(<<pcc>>.<<asr_perm>>) when required for CSR access or execution of <<MRET_CHERI>>/<<SRET_CHERI>>
6+| *Load additional exception checks*
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_tag}      | `auth_cap` valid tag       | not(`auth_cap.tag`)
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_seal}     | `auth_cap` seal            | isCapSealed(`auth_cap`)
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_perm}     | `auth_cap` permission      | not(`auth_cap`.<<r_perm>>)
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_inv_addr} | `auth_cap` invalid address | Address is invalid (see <<section_invalid_addr_conv>>)
| all loads        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_bounds}   | `auth_cap` bounds          | Any byte of load access out of `auth_cap` bounds
| capability loads | 4                    | N/A                     | N/A                          | load address misaligned    | Misaligned capability load
6+| *Store/atomic/cache-block-operation additional exception checks*
| all stores, all atomics, all CBOs              | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_tag}    |`auth_cap` valid tag  | not(`auth_cap.tag`)
| all stores, all atomics, all CBOs              | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_seal}   |`auth_cap` seal       | isCapSealed(`auth_cap`)
| all atomics, CBO.INVAL*                        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_perm}   |`auth_cap` permission | not(`auth_cap`.<<r_perm>>)
| all stores, all atomics, CBO.INVAL*, CBO.ZERO* | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_perm}   |`auth_cap` permission | not(`auth_cap`.<<w_perm>>)
| CBO.CLEAN*, CBO.FLUSH*                         | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_perm}   |`auth_cap` permission | not(`auth_cap`.<<r_perm>>) and not(`auth_cap`.<<w_perm>>)
| all stores, all atomics, all CBOs              | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_inv_addr} |`auth_cap` invalid address | Address is invalid (see <<section_invalid_addr_conv>>)
| all stores, all atomics                        | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_bounds}   |`auth_cap` bounds          | any byte of access out of `auth_cap` bounds
| CBO.ZERO*, CBO.INVAL*                          | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_bounds}   |`auth_cap` bounds          | any byte of cache block out of `auth_cap` bounds
| CBO.CLEAN*, CBO.FLUSH*                         | {cheri_excep_mcause} | {cheri_excep_type_data} | {cheri_excep_cause_bounds}   |`auth_cap` bounds          | all bytes of cache block out of `auth_cap` bounds
| CBO.INVAL*                                     | {cheri_excep_mcause} | {cheri_excep_type_pcc}  | {cheri_excep_cause_perm}     |<<pcc>> permission         | not(<<pcc>>.<<asr_perm>>)
| capability stores                              | 6                    | N/A                     | N/A                          |capability alignment       | Misaligned capability store
|=========================================================================================

NOTE: <<CBO_ZERO_CHERI>> is performed as a cache block wide store.  All
CMOs operate on the cache block which contains the address.  Prefetch instructions check
that the authorizing capability is has its valid tag set, is not sealed, has the required permission (<<r_perm>>,
<<w_perm>>, <<x_perm>>) corresponding to the instruction, and has bounds which
include at least one byte of the cache block; if any check fails, the prefetch
is not performed but no exception is generated.

[#CHERI_SPEC,reftext="CHERI Exceptions and speculative execution"]
=== CHERI Exceptions and speculative execution

#should be non-normative - and needs more details - move to appendix?#

CHERI adds architectural guarantees that can prove to be microarchitecturally useful.
Speculative-execution attacks can -- among other factors -- rely on instructions that fail CHERI permission checks not to take effect.
When implementing any of the extensions proposed here, microarchitects need to carefully consider the interaction of late-exception raising and side-channel attacks.

[#section_pma]
=== Physical Memory Attributes (PMA)

Typically, only parts of the entire memory space need to support CHERI valid tags.
Therefore, it is desirable that harts supporting {cheri_base_ext_name} extend PMAs with Physical Memory Attributes indicating whether a memory region allows storing CHERI valid tags.
If they are not supported, then what the behavior is when attempting to access them.

There are three levels of support:

.CHERI PMAs
[#cheri_pmas]
[width="100%",options=header]
|=========================================================================================
| PMA                     | Load Behavior       | Store Behavior                         | Comment
| _CHERI Valid Tag_       | Load valid tag      | Store valid tag                        | Tagged memory supporting valid tags
| _CHERI Valid Tag Strip_ | Load zero valid tag | Ignore stored valid tag                | No support for valid tags, ignore them
| _CHERI Valid Tag Fault_ | Load zero valid tag | Store/AMO Access Fault on valid tag^1^ | No support for valid tags, trap on storing one
|=========================================================================================

^1^ The access fault is triggered on all capability stores or atomics such as <<SC>> or <<AMOSWAP_C>> when <<c_perm>> and <<w_perm>> are granted and the valid tag is set to one.

Memory regions that do not have the _CHERI Valid Tag_ PMA do not require storage for valid tags.

[#section_vm]
=== Virtual Memory

CHERI checks are made on the effective address according to the current translation scheme.
I.e., on the virtual address if translation is enabled or the physical address if translation is disabled.

Implicit memory accesses made by the page table walker are not subject to CHERI checks.

NOTE: A future extension may add CHERI checks to the page table walker.

[#section_cheri_disable]
== "{cheri_priv_m_reg_enable_ext}" Extension, Version 1.0

ifdef::cheri_v9_annotations[]
NOTE: *CHERI v9 Note:* This feature is new and different from CHERI v9's
per-privilege enable bits.

NOTE: *CHERI v9 Note:* The rules for excepting have been tightened here. Also,
it is not possible to disable CHERI checks completely.
endif::[]

CAUTION: #ARC-QUESTION: The CBZE, CBIE etc. bits are specified by Zicbo*, can this be defined by {cheri_priv_m_ext}/{cheri_priv_s_ext}+{cheri_default_ext_name} instead of adding a new priv extension?#

When using a system with {cheri_default_ext_name}, it may be desirable to disabling CHERI register and instruction access to some (or all) privilege levels such that they operate as a RV32I/RV64I system without any observable presence of CHERI features.
{cheri_priv_m_reg_enable_ext} includes functions to disable explicit access to CHERI
registers and instructions.
The {cheri_priv_m_reg_enable_ext} extension makes the `CRE` bit of <<mseccfg>>, <<menvcfg>>, and <<senvcfg>> writable.

IMPORTANT: If {cheri_base_ext_name} is supported and {cheri_default_ext_name} is not supported, then {cheri_priv_m_reg_enable_ext} must also not be supported.
In this case all CRE bits are hardwired to 1 and access to CHERI registers is always permitted.
This allows implementing a hart that always runs in {cheri_cap_mode_name}.

CHERI register access is disabled if

* XLEN in the current mode is less than MXLEN, or
* the endianness in the current mode is not the reset value of <<mstatus_cheri>>.MBE, or
* the effective CRE for the current privilege is 0.

The effective CRE for the current privilege is:

* Machine: `<<mseccfg>>.CRE`
* Supervisor: `<<mseccfg>>.CRE & <<menvcfg>>.CRE`
* User: `<<mseccfg>>.CRE & <<menvcfg>>.CRE & <<senvcfg>>.CRE`

NOTE: The effective CRE is always 1 in debug mode.

NOTE: On reset CHERI register access is disabled (<<mseccfg>>.CRE resets to zero).

The following occurs when executing code in a privilege mode that has CHERI register access disabled:

* Instructions that access *c* registers (implicitly or explicitly)
cause illegal instruction exceptions
+
NOTE: The only instruction added by {cheri_base_ext_name} that does not access capability state is <<CRAM>>, all others are disabled.
* Executing CSR instructions accessing any CSR added by any CHERI extension ({cheri_default_ext_name}, {cheri_priv_m_ext}, {cheri_priv_s_ext}, {cheri_priv_h_ext}) causes an illegal instruction exception
* Executing CSR instructions accessing any CSR extended to CLEN only allows XLEN access.
* All allowed instructions execute as if the CHERI execution mode is {cheri_int_mode_name}.
// FIXME: there should be no way to observe the M bit, do we need to mentions this?
// The mode bit in <<pcc>> is treated as if it was zero while CHERI register access is disabled.

Disabling CHERI register access has no effect on implicit accesses or security checks.
The last capability written to <<pcc>> and <<ddc>> before disabling CHERI register access will be used to authorize instruction execution and data memory accesses.

[NOTE]
====
Disabling CHERI register access prevents low-privileged {cheri_int_mode_name} software
from interfering with the correct operation of higher-privileged {cheri_int_mode_name} software
that do not perform <<ddc>> switches on trap entry and return.

Disabling CHERI register access allows harts supporting CHERI to be fully
compatible with standard RISC-V, so CHERI instructions, such as <<CRAM>>, that
do not change the state of CHERI CSRs raise exceptions when CRE=0.
This is the default behavior on reset.
====

xref:cheri_behavior_cre_mode[xrefstyle=short] summarizes the behavior of a hart
in connection with the <<section_cheri_disable,CRE>> and the <<cheri_execution_mode>> while in a privilege other than debug mode.

.Hart's behavior depending on the effective <<section_cheri_disable,CRE>> and <<cheri_execution_mode>>
[#cheri_behavior_cre_mode,width=100%,options=header,align=center,%autowidth,cols="40,20,20,20"]
|==============================================================================
| | CRE=0, M-bit=X^1^ | CRE=1, M-bit={int_mode_value} | CRE=1, M-bit={cap_mode_value}
| Authorizing capability for memory accesses | <<ddc>> or <<pcc>> | <<ddc>> or <<pcc>> | Instruction's capability operand
| New CHERI CSR Access Width                | ✘                 | CLEN                  | CLEN
| Extended CHERI CSR Access Width      | XLEN              | XLEN                  | CLEN
| CHERI Instructions Allowed           | ✘                 | ✔                    | ✔
| Compressed Instructions Remapped     | No                | No                    | Yes^2^
| Summary                              | **_Fully RISC-V compatible_**^3^ | **{cheri_int_mode_name}** | **{cheri_cap_mode_name}**
|==============================================================================

^1^ M-bit is irrelevant when CRE=0. +
^2^ See xref:legacy_mnemonics[xrefstyle=short] for a list of remapped
instructions. +
^3^ The hart is fully compatible with standard RISC-V when CRE=0 provided that <<pcc>>, <<mtvecc>>, <<mepcc>>, <<stvecc>>, <<sepcc>>, <<vstvecc>>, <<vsepcc>> and <<ddc>> have not been changed from the default reset state (i.e., hold the <<infinite-cap>> capability).


[#section_cheri_dyn_xlen]
== "{cheri_priv_m_dyn_xlen_ext}" Extension, Version 1.0

{cheri_priv_m_dyn_xlen_ext} eliminates some restrictions for SXL and UXL imposed in {cheri_priv_m_ext} to allow implementations supporting multiple base ISAs.
This extension allows the SXL, UXL, MBE, SBE, and UBE fields of <<mstatus_cheri>> to be writable (which is prohibited by {cheri_priv_m_ext} otherwise).

CAUTION: #ARC-QUESTION: Should this extension be folded into the {cheri_priv_m_reg_enable_ext} extension?#

Changing XLEN::
Setting the SXL or UXL field to a value that is not MXLEN disables most CHERI features and instructions, as described in xref:section_cheri_disable[xrefstyle=short], while in that privilege mode.
+
NOTE: If CHERI register access must be disabled in a mode for security reasons, software should set CRE to 0 regardless of the SXL and UXL fields.
+
Whenever XLEN in any mode is set to a value less than MXLEN, standard RISC-V rules from cite:[riscv-unpriv-spec] are followed.
This means that all operations must ignore source operand register bits above the configured XLEN, and must sign-extend results to fill all MXLEN bits in the destination register.
Similarly, *pc* bits above XLEN are ignored, and when the *pc* is written, it is sign-extended to fill MXLEN.
The integer writing rule from CHERI is followed, so that every register write also zeroes the metadata and valid tag of the
destination register.
+
However, CHERI operations and security checks will continue using the entire hardware register (i.e., CLEN bits) to correctly decode capability bounds.

Changing endianness::
Setting the MBE, SBE, or UBE field to a value that is not the reset value of MBE disables most CHERI features and instructions, as described in xref:section_cheri_disable[xrefstyle=short], while in that privilege mode.


[#section_priv_cheri_vmem]
== "{cheri_priv_vmem_ext}" Extension, Version 1.0

RISC-V's page-based virtual-memory management is generally orthogonal to CHERI.
In {cheri_base_ext_name}, capability addresses are interpreted with respect to the privilege level of the processor in line with RISC-V's handling of integer addresses.
In machine mode, capability addresses are generally interpreted as physical addresses; if the <<mstatus_cheri>> MPRV flag is asserted, then data accesses (but not instruction accesses) will be interpreted as if performed by the privilege mode in <<mstatus_cheri>>'s MPP.
In supervisor and user modes, capability addresses are interpreted as dictated by the current *satp* configuration: addresses are virtual if paging is enabled and physical if not.

{cheri_priv_vmem_ext} requires that the <<pcc>> grants the <<asr_perm>> to change the page-table root *satp* and other virtual-memory parameters as described in xref:supervisor-level-csrs-section[xrefstyle=short].

[#section_cw_bit]
=== Capability Write (CW) Bit

{cheri_priv_vmem_ext} defines the Capability Write (CW) bit in Page Table Entries (PTEs) for Sv39, Sv48, and Sv57 virtual memory systems on RV64 harts. The CW bit controls whether capabilities with their valid tag set can be written to a virtual page.

NOTE: _Sv32_ does not have any spare PTE bits, and so this bit does not exist for RV32.

IMPORTANT: Any hart that supports {cheri_base_ext_name} and at least one of the Sv39, Sv48, and Sv57 virtual memory translation schemes must also implement {cheri_priv_vmem_ext}.

[#limit_cap_prop]
==== Limiting Capability Propagation

CAUTION: #ARC-QUESTION: Is this too much rationale? Should it be trimmed down and just describe the mechanism?#

Page table enforcement can allow the operating system to limit the flow of capabilities between processes.
It is highly desirable that a process should only possess capabilities that have been issued for that address space by the operating system.
Unix processes may share memory for efficient communication, but capability pointers must not be shared across these channels into a foreign address space.
An operating system might defend against this by only issuing a capability to the shared region that does not grant the load/store capability permission.
However, there are circumstances where portions of general-purpose, mmapped^*^ memory become shared, and the operating system must prevent future capability communication through those pages.
This is not possible without restructuring software, as the capability for the original allocation, which spans both shared memory and private memory, would need to be deleted and replaced with a list of distinct capabilities with appropriate permissions for each range.
Such a change would not be transparent to the program.
Such sharing through virtual memory is on the page granularity, so preventing capability writes with a PTE permission is a natural solution.

^*^ _allocated using mmap_

[#cheri_pte_fault]
=== CHERI PTE page faults

CHERI adds the concept of _CHERI PTE page faults_.
These reuse the load page fault and store/AMO page fault exception causes, and write additional information to <<mtval2>>/<<stval2>>/<<vstval2>>.

Page faults are considered to be _CHERI PTE page faults_ if the `Xtval2` register is written with a non-zero value.

NOTE: It is possible for both a _normal_ page fault and a _CHERI PTE page fault_ to both trigger at once, as represented in the `Xtval2` value, as shown in <<mtval2-page-fault>>.

NOTE: Where two stage translation is enabled, the _CHERI PTE page fault_ is only raised when the second stage translation has completed, and so is prioritized below guest page faults.

All RV64 harts with virtual memory can raise _CHERI store/AMO PTE page faults_.
Only harts which implement {cheri_priv_vmem_ext} can raise _CHERI load PTE page faults_.

==== Extending the Page Table Entry Format

The page table entry format remains unchanged for Sv32.
However, a new bit, Capability Write (CW), is added to leaf PTEs in Sv39, Sv48 and Sv57 as shown in xref:sv39pte_cw[xrefstyle=short], xref:sv48pte_cw[xrefstyle=short] and xref:sv57pte_cw[xrefstyle=short] respectively.
For non-leaf PTEs this bit remains reserved and must be cleared by software for forward compatibility, or else a page-fault exception is raised.
Additionally, if the hypervisor extension is enabled this bit remains reserved for leaf and non-leaf PTEs used in guest address translation.

CAUTION: #ARC-QUESTION: The current bit 60 has been allocated by Svrsw60t59b, should we use bit 58?#

.Sv39 page table entry
[#sv39pte_cw]
include::img/sv39pte_cw.edn[]

.Sv48 page table entry
[#sv48pte_cw]
include::img/sv48pte_cw.edn[]

.Sv57 page table entry
[#sv57pte_cw]
include::img/sv57pte_cw.edn[]

The CW bit indicates whether reading or writing capabilities with the valid tag set to the virtual page is permitted.
When the CW bit is set, capabilities are written as usual.

If the CW bit is clear then:

* When a capability load or AMO instruction is executed, the implementation clears the valid tag bit of the capability read from the virtual page.
* A <<cheri_pte_fault,CHERI store/AMO PTE page fault>> exception is raised when a capability store or AMO instruction is executed and the valid tag bit of the capability being written is set.

[[pte_cw_store_summary]]
.Summary of Store CW behavior in the PTEs
[%autowidth,float="center",align="center",cols="<,<",options="header"]
|===
|PTE.CW |Store/AMO
| 0     | <<cheri_pte_fault,CHERI store/AMO PTE page fault>> if stored valid tag is set
| 1     | Normal operation
|===

[NOTE]
====
The valid tag bit of the stored capability is checked _after_ it is potentially cleared due to missing permissions.
Therefore, the behavior in this section isn't relevant if:

* The authorizing capability doesn't have <<c_perm>>.
* Insufficient <<sl_perm>> has cleared the valid tag of the to-be-stored capability.
====

[#section_invalid_addr_conv,reftext="Invalid address conversion"]
=== Invalid Address Handling

When address translation is in effect and XLEN=64, the upper bits of virtual
memory addresses must match for the address to be valid:

* For Sv39, bits [63:39] must equal bit 38
* For Sv48, bits [63:48] must equal bit 47
* For Sv57, bits [63:57] must equal bit 56

RISC-V permits that CSRs holding addresses, such as <<mtvec>> and <<mepc>>
(see xref:CSR_exevectors[xrefstyle=short]) as well as pc, need not
hold all possible invalid addresses. Implementations may convert an invalid
address into some other invalid address that the register is capable of holding.
Therefore, implementations often support area and power optimizations by
compressing invalid addresses in a lossy fashion.

Where compressed addresses are implemented, there must be also sufficient address bits
to represent all valid physical addresses. The following description is for both
virtual and physical addresses.

NOTE: Compressing invalid addresses allows implementations to reduce the number
of flip-flops required to hold some CSRs, such as <<mtvec>>. In CHERI, invalid
addresses may also be used to reduce the number of bits to compare during a
bounds check, for example, to 40 bits if using Sv39, assuming that this also
covers all valid physical addresses.

NOTE: Care needs to be taken not to truncate physical addresses to the implemented
number of physical addresses bits without also checking that the capability is still
valid following the rules in this section, as the capability bounds and representable range
always cover the entire MXLEN-bit address bits, but the address is likely not to.

However, the bounds encoding of capabilities in {cheri_base_ext_name} depends
on the address value, so implementations must not convert invalid addresses to
other arbitrary invalid address in an unrestricted manner. The remainder of
this section describes how invalid address handling must be supported in
{cheri_base_ext_name} when accessing CSRs, branching and jumping, and
accessing memory.

==== Updating CSRs

Some capability-holding CSRs need not be able to hold all invalid virtual addresses.
Prior to writing to those CSRs, implementations may convert an invalid address into some other invalid address that the CSR is capable of holding.
This is problematic for CHERI as updating the address may invalidate the bounds as a result, if the bounds are not those of the <<infinite-cap>> capability.

Some situations may require that a CSR may be updated to hold a capability with an invalid address:

* executing instructions, such as <<CSRRW_CHERI>>
* hardware updates to CSRs such as storing the <<pcc>> (which becomes capability A) into
 <<mepcc>>/<<sepcc>> etc. when taking an exception.

In order to satisfy the definitions of such CSRs and preserve capability system invariants, the following procedure must be used as part of write-back to the CSR:

. If A's address is invalid and A does not have infinite bounds (see
xref:section_cap_encoding[xrefstyle=short]), then A's valid tag is set to zero.
. Write the final (potentially modified) version of capability A to the CSR e.g.
<<mtvecc>>, <<mepcc>>, etc.

NOTE: When A's address is invalid and happens to match an invalid address which the CSR
can hold, then it is implementation defined whether to clear A's valid tag.

==== Branches and Jumps

Control transfer instructions jump or branch to a capability A which can be:

* <<pcc>> for branches, direct jumps and any branch when in
{cheri_int_mode_name} (see xref:section_cheri_hybrid_ext[xrefstyle=short]).
* The capability in the *c* input register of a jump when in
{cheri_cap_mode_name} (see xref:section_cheri_hybrid_ext[xrefstyle=short]).

The following procedure must be used when jumping or branching to the target
capability A if the <<pcc>> cannot hold all invalid addresses:

. Calculate the effective target address T of the jump or branch as required by
the instruction's behavior.
. If T is invalid and A does not have infinite bounds (see
xref:section_cap_encoding[xrefstyle=short]), then set A's valid tag to zero.
 This will cause a CHERI Valid Tag Violation when executing the target instruction.
. If T is invalid and A has infinite bounds (see
xref:section_cap_encoding[xrefstyle=short]), then A's valid tag is unchanged and T is
written into A's address field. Attempting to execute the instruction at
address T causes an instruction access fault or page fault as is usual in RISC-V.
. Otherwise T is valid and the instruction behaves as normal.

NOTE: RISC-V harts that do not support {cheri_base_ext_name} normally raise an
instruction access fault or page fault after jumping or branching to an invalid address.
Therefore, {cheri_base_ext_name} aims to preserve that behavior to ensure that
harts supporting {cheri_base_ext_name} and {cheri_default_ext_name} are fully
compatible with RISC-V harts provided that <<pcc>> and <<ddc>> are set to the
<<infinite-cap>> capability.

==== Memory Accesses

The following procedure must be used while loading or storing to memory with a
capability A when the implementation supports invalid address optimizations:

. Calculate the effective address range R of the memory access as required by the
instruction's behavior.
. If any byte in R is invalid and A does not have infinite bounds (see
xref:section_cap_encoding[xrefstyle=short]), then the instruction causes
a CHERI fault; the _CHERI data_ fault is reported in the TYPE field and invalid
address violation is reported in the CAUSE field of <<mtval2>>, <<stval2>> or <<vstval2>>.
. If any byte in R is invalid and A has infinite bounds (see xref:section_cap_encoding[xrefstyle=short]),
the hart will raise an access fault or page fault as is usual in RISC-V.
. Otherwise all bytes in R are valid and the instruction behaves as normal.
